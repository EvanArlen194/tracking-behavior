{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e90ce1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:29.931840Z",
     "iopub.status.busy": "2025-11-05T15:39:29.931622Z",
     "iopub.status.idle": "2025-11-05T15:39:35.424078Z",
     "shell.execute_reply": "2025-11-05T15:39:35.423183Z"
    },
    "papermill": {
     "duration": 5.497579,
     "end_time": "2025-11-05T15:39:35.425278",
     "exception": false,
     "start_time": "2025-11-05T15:39:29.927699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy available - GPU acceleration enabled\n",
      "Available RAM: 31.4 GB\n",
      "Current usage: 4.0%\n",
      "GPU Memory: 15.9 GB\n"
     ]
    }
   ],
   "source": [
    "validate_or_submit = 'submit'\n",
    "verbose = True\n",
    "SEED = 42\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import polars as pl\n",
    "from scipy import signal, stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import psutil\n",
    "import pickle\n",
    "\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator, clone\n",
    "from sklearn.model_selection import cross_val_predict, GroupKFold, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(SEED)\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    CUPY_AVAILABLE = True\n",
    "    print(\"CuPy available - GPU acceleration enabled\")\n",
    "except:\n",
    "    CUPY_AVAILABLE = False\n",
    "    print(\"CuPy not available - using CPU fallback\")\n",
    "\n",
    "print(f\"Available RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "print(f\"Current usage: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "if CUPY_AVAILABLE:\n",
    "    print(f\"GPU Memory: {cp.cuda.Device(0).mem_info[1] / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a280c17d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:35.431516Z",
     "iopub.status.busy": "2025-11-05T15:39:35.431170Z",
     "iopub.status.idle": "2025-11-05T15:39:35.439598Z",
     "shell.execute_reply": "2025-11-05T15:39:35.439067Z"
    },
    "papermill": {
     "duration": 0.012496,
     "end_time": "2025-11-05T15:39:35.440593",
     "exception": false,
     "start_time": "2025-11-05T15:39:35.428097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StratifiedSubsetClassifier(ClassifierMixin, BaseEstimator):\n",
    "    def __init__(self, estimator, n_samples, random_state=42):\n",
    "        self.estimator = estimator\n",
    "        self.n_samples = n_samples\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if len(X) <= self.n_samples:\n",
    "            self.estimator.fit(X, y)\n",
    "        else:\n",
    "            from sklearn.model_selection import StratifiedShuffleSplit\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=min(self.n_samples, len(X)), random_state=self.random_state)\n",
    "            try:\n",
    "                for train_idx, _ in sss.split(X, y):\n",
    "                    X_sample = X.iloc[train_idx] if hasattr(X, 'iloc') else X[train_idx]\n",
    "                    y_sample = y[train_idx]\n",
    "                    self.estimator.fit(X_sample, y_sample)\n",
    "                    del X_sample, y_sample\n",
    "            except:\n",
    "                np.random.seed(self.random_state)\n",
    "                downsample = max(len(X) // self.n_samples, 1)\n",
    "                X_ds = X[::downsample]\n",
    "                y_ds = y[::downsample]\n",
    "                self.estimator.fit(X_ds, y_ds)\n",
    "                del X_ds, y_ds\n",
    "\n",
    "        self.classes_ = self.estimator.classes_\n",
    "        gc.collect()\n",
    "        if CUPY_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if len(self.classes_) == 1:\n",
    "            return np.full((len(X), 1), 1.0)\n",
    "        proba = self.estimator.predict_proba(X)\n",
    "        return proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = self.estimator.predict(X)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bee6099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:35.446072Z",
     "iopub.status.busy": "2025-11-05T15:39:35.445843Z",
     "iopub.status.idle": "2025-11-05T15:39:36.156488Z",
     "shell.execute_reply": "2025-11-05T15:39:36.155541Z"
    },
    "papermill": {
     "duration": 0.714706,
     "end_time": "2025-11-05T15:39:36.157696",
     "exception": false,
     "start_time": "2025-11-05T15:39:35.442990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory after loading: 4.4%\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/train.csv')\n",
    "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "train_without_mabe22 = train.query(\"~ lab_id.str.startswith('MABe22_')\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/test.csv')\n",
    "body_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n",
    "\n",
    "drop_body_parts = ['headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright',\n",
    "                   'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright',\n",
    "                   'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint']\n",
    "\n",
    "arena_metadata = {}\n",
    "for _, row in pd.concat([train, test]).iterrows():\n",
    "    arena_metadata[row['video_id']] = {\n",
    "        'pix_per_cm': row['pix_per_cm_approx'],\n",
    "        'fps': row.get('fps', 30),\n",
    "        'lab_id': row['lab_id']\n",
    "    }\n",
    "\n",
    "gc.collect()\n",
    "print(f\"Memory after loading: {psutil.virtual_memory().percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddde63c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:36.164328Z",
     "iopub.status.busy": "2025-11-05T15:39:36.163952Z",
     "iopub.status.idle": "2025-11-05T15:39:36.179099Z",
     "shell.execute_reply": "2025-11-05T15:39:36.178588Z"
    },
    "papermill": {
     "duration": 0.019732,
     "end_time": "2025-11-05T15:39:36.180193",
     "exception": false,
     "start_time": "2025-11-05T15:39:36.160461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_coordinates(x, y, pix_per_cm, arena_width_cm=120, arena_height_cm=120):\n",
    "    x_norm = np.clip(x / pix_per_cm, 0, arena_width_cm)\n",
    "    y_norm = np.clip(y / pix_per_cm, 0, arena_height_cm)\n",
    "    return x_norm, y_norm\n",
    "\n",
    "def generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n",
    "    assert traintest in ['train', 'test']\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "    for _, row in dataset.iterrows():\n",
    "\n",
    "        lab_id = row.lab_id\n",
    "        if lab_id.startswith('MABe22'):\n",
    "            continue\n",
    "        video_id = row.video_id\n",
    "\n",
    "        if type(row.behaviors_labeled) != str:\n",
    "            if verbose:\n",
    "                print('No labeled behaviors:', lab_id, video_id)\n",
    "            continue\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "\n",
    "        try:\n",
    "            vid = pd.read_parquet(path, columns=['video_frame', 'mouse_id', 'bodypart', 'x', 'y'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n",
    "\n",
    "        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n",
    "\n",
    "        if pvid.isna().any().any():\n",
    "            if verbose and traintest == 'test':\n",
    "                print('video with missing values', video_id, traintest, len(vid), 'frames')\n",
    "\n",
    "        del vid\n",
    "        gc.collect()\n",
    "\n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n",
    "        pvid = pvid.astype(np.float32)\n",
    "\n",
    "        for mouse_id in np.unique(pvid.columns.get_level_values('mouse_id')):\n",
    "            for bodypart_name in pvid[mouse_id].columns.get_level_values(0).unique():\n",
    "                if 'x' in pvid[mouse_id][bodypart_name].columns:\n",
    "                    x_vals = pvid[(mouse_id, bodypart_name, 'x')]\n",
    "                    y_vals = pvid[(mouse_id, bodypart_name, 'y')]\n",
    "                    x_norm, y_norm = normalize_coordinates(x_vals, y_vals, row.pix_per_cm_approx)\n",
    "                    pvid[(mouse_id, bodypart_name, 'x')] = x_norm\n",
    "                    pvid[(mouse_id, bodypart_name, 'y')] = y_norm\n",
    "\n",
    "        vid_behaviors = json.loads(row.behaviors_labeled)\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "\n",
    "        if traintest == 'train':\n",
    "            try:\n",
    "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
    "            except FileNotFoundError:\n",
    "                del pvid\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "        if generate_single:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\")\n",
    "            for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n",
    "                try:\n",
    "                    mouse_id = int(mouse_id_str[-1])\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n",
    "                    single_mouse = pvid.loc[:, mouse_id].copy()\n",
    "                    single_mouse_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': mouse_id_str,\n",
    "                        'target_id': 'self',\n",
    "                        'video_frame': single_mouse.index,\n",
    "                        'fps': row.get('fps', 30)\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index, dtype=np.float32)\n",
    "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print('- test single', video_id, mouse_id)\n",
    "                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "        if generate_pair:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n",
    "            if len(vid_behaviors_subset) > 0:\n",
    "                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2):\n",
    "                    agent_str = f\"mouse{agent}\"\n",
    "                    target_str = f\"mouse{target}\"\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
    "                    if len(vid_agent_actions) == 0:\n",
    "                        continue\n",
    "\n",
    "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B']).copy()\n",
    "                    mouse_pair_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': agent_str,\n",
    "                        'target_id': target_str,\n",
    "                        'video_frame': mouse_pair.index,\n",
    "                        'fps': row.get('fps', 30)\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index, dtype=np.float32)\n",
    "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print('- test pair', video_id, agent, target)\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions\n",
    "\n",
    "        del pvid\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d9c253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:36.186574Z",
     "iopub.status.busy": "2025-11-05T15:39:36.186178Z",
     "iopub.status.idle": "2025-11-05T15:39:36.221102Z",
     "shell.execute_reply": "2025-11-05T15:39:36.220422Z"
    },
    "papermill": {
     "duration": 0.039395,
     "end_time": "2025-11-05T15:39:36.222111",
     "exception": false,
     "start_time": "2025-11-05T15:39:36.182716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_rolling(series, window, func, min_periods=None):\n",
    "    if min_periods is None:\n",
    "        min_periods = max(1, window // 4)\n",
    "    return series.rolling(window, min_periods=min_periods, center=True).apply(func, raw=True)\n",
    "\n",
    "def add_spectral_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "\n",
    "    for window in [60, 120]:\n",
    "        if len(speed) >= window:\n",
    "            speed_chunk = speed.rolling(window, min_periods=window//2).apply(\n",
    "                lambda x: np.sum(np.abs(np.fft.rfft(x - x.mean())[:5])), raw=True\n",
    "            )\n",
    "            X[f'fft_pwr{window}'] = speed_chunk\n",
    "\n",
    "    del speed\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_curvature_features(X, center_x, center_y):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    acc_x = vel_x.diff()\n",
    "    acc_y = vel_y.diff()\n",
    "\n",
    "    cross_prod = vel_x * acc_y - vel_y * acc_x\n",
    "    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n",
    "    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)\n",
    "\n",
    "    X['curv_m30'] = curvature.rolling(30, min_periods=5).mean()\n",
    "    X['curv_m60'] = curvature.rolling(60, min_periods=10).mean()\n",
    "    X['curv_s30'] = curvature.rolling(30, min_periods=5).std()\n",
    "    X['curv_max60'] = curvature.rolling(60, min_periods=10).max()\n",
    "\n",
    "    angle = np.arctan2(vel_y, vel_x)\n",
    "    angle_change = np.abs(angle.diff())\n",
    "    X['turn_r30'] = angle_change.rolling(30, min_periods=5).sum()\n",
    "    X['turn_r60'] = angle_change.rolling(60, min_periods=10).sum()\n",
    "    X['turn_m30'] = angle_change.rolling(30, min_periods=5).mean()\n",
    "    X['turn_std30'] = angle_change.rolling(30, min_periods=5).std()\n",
    "\n",
    "    del vel_x, vel_y, acc_x, acc_y, cross_prod, vel_mag, curvature, angle, angle_change\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_multiscale_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "\n",
    "    scales = [5, 10, 20, 40, 80, 160]\n",
    "    for scale in scales:\n",
    "        if len(speed) >= scale:\n",
    "            min_p = max(1, scale//4)\n",
    "            X[f'sp_m{scale}'] = speed.rolling(scale, min_periods=min_p).mean()\n",
    "            X[f'sp_s{scale}'] = speed.rolling(scale, min_periods=min_p).std()\n",
    "            X[f'sp_mx{scale}'] = speed.rolling(scale, min_periods=min_p).max()\n",
    "            X[f'sp_mn{scale}'] = speed.rolling(scale, min_periods=min_p).min()\n",
    "\n",
    "    if len(scales) >= 2:\n",
    "        for i in range(len(scales)-1):\n",
    "            if f'sp_m{scales[i]}' in X.columns and f'sp_m{scales[i+1]}' in X.columns:\n",
    "                X[f'sp_rt{scales[i]}_{scales[i+1]}'] = X[f'sp_m{scales[i]}'] / (X[f'sp_m{scales[i+1]}'] + 1e-6)\n",
    "\n",
    "    del speed\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_state_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "    speed_ma = speed.rolling(15, min_periods=5).mean()\n",
    "\n",
    "    try:\n",
    "        speed_states = pd.cut(speed_ma, bins=[-np.inf, 0.5, 2.0, 5.0, np.inf], labels=[0, 1, 2, 3]).astype(float)\n",
    "\n",
    "        for window in [30, 60, 120, 240]:\n",
    "            if len(speed_states) >= window:\n",
    "                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n",
    "                X[f'trans_{window}'] = state_changes.rolling(window, min_periods=10).sum()\n",
    "                X[f'state_m{window}'] = speed_states.rolling(window, min_periods=10).mean()\n",
    "                X[f'state_s{window}'] = speed_states.rolling(window, min_periods=10).std()\n",
    "\n",
    "        del speed_states, state_changes\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    del speed, speed_ma\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_longrange_features(X, center_x, center_y):\n",
    "    for window in [60, 120, 240]:\n",
    "        if len(center_x) >= window:\n",
    "            X[f'x_ml{window}'] = center_x.rolling(window, min_periods=20).mean()\n",
    "            X[f'y_ml{window}'] = center_y.rolling(window, min_periods=20).mean()\n",
    "            X[f'x_sl{window}'] = center_x.rolling(window, min_periods=20).std()\n",
    "            X[f'y_sl{window}'] = center_y.rolling(window, min_periods=20).std()\n",
    "\n",
    "    for span in [30, 60, 120]:\n",
    "        X[f'x_e{span}'] = center_x.ewm(span=span, min_periods=1).mean()\n",
    "        X[f'y_e{span}'] = center_y.ewm(span=span, min_periods=1).mean()\n",
    "\n",
    "    dist_from_center = np.sqrt((center_x - center_x.mean())**2 + (center_y - center_y.mean())**2)\n",
    "    for window in [30, 60, 120]:\n",
    "        X[f'cen_d{window}'] = dist_from_center.rolling(window, min_periods=5).mean()\n",
    "        X[f'cen_s{window}'] = dist_from_center.rolling(window, min_periods=5).std()\n",
    "\n",
    "    del dist_from_center\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_interaction_features(X, mouse_pair, avail_A, avail_B):\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "\n",
    "    rel_x = mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x']\n",
    "    rel_y = mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y']\n",
    "    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n",
    "\n",
    "    A_vx = mouse_pair['A']['body_center']['x'].diff()\n",
    "    A_vy = mouse_pair['A']['body_center']['y'].diff()\n",
    "    B_vx = mouse_pair['B']['body_center']['x'].diff()\n",
    "    B_vy = mouse_pair['B']['body_center']['y'].diff()\n",
    "\n",
    "    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n",
    "    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n",
    "\n",
    "    for window in [15, 30, 60, 120]:\n",
    "        X[f'A_ld{window}'] = A_lead.rolling(window, min_periods=5).mean()\n",
    "        X[f'B_ld{window}'] = B_lead.rolling(window, min_periods=5).mean()\n",
    "        X[f'A_ld_s{window}'] = A_lead.rolling(window, min_periods=5).std()\n",
    "        X[f'B_ld_s{window}'] = B_lead.rolling(window, min_periods=5).std()\n",
    "\n",
    "    approach = -rel_dist.diff()\n",
    "    chase = approach * B_lead\n",
    "    for window in [15, 30, 60, 120]:\n",
    "        X[f'chase_{window}'] = chase.rolling(window, min_periods=5).mean()\n",
    "        X[f'appr_{window}'] = approach.rolling(window, min_periods=5).mean()\n",
    "        X[f'chase_s{window}'] = chase.rolling(window, min_periods=5).std()\n",
    "\n",
    "    rel_angle = np.arctan2(rel_y, rel_x)\n",
    "    rel_angle_change = np.abs(rel_angle.diff())\n",
    "    for window in [30, 60, 120]:\n",
    "        X[f'rel_ang{window}'] = rel_angle_change.rolling(window, min_periods=5).sum()\n",
    "        X[f'rel_ang_m{window}'] = rel_angle_change.rolling(window, min_periods=5).mean()\n",
    "\n",
    "    del rel_x, rel_y, rel_dist, A_vx, A_vy, B_vx, B_vy, A_lead, B_lead, approach, chase, rel_angle, rel_angle_change\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_spatial_features(X, center_x, center_y):\n",
    "    grid_x = (center_x / 10).fillna(0).astype(int)\n",
    "    grid_y = (center_y / 10).fillna(0).astype(int)\n",
    "\n",
    "    for window in [60, 120, 240]:\n",
    "        if len(grid_x) >= window:\n",
    "            grid_changes = ((grid_x != grid_x.shift(1)) | (grid_y != grid_y.shift(1))).astype(float)\n",
    "            X[f'grid_ch{window}'] = grid_changes.rolling(window, min_periods=10).sum()\n",
    "\n",
    "    X['x_quad'] = (center_x > center_x.median()).astype(float)\n",
    "    X['y_quad'] = (center_y > center_y.median()).astype(float)\n",
    "\n",
    "    wall_dist = np.minimum(\n",
    "        np.minimum(center_x, 120 - center_x),\n",
    "        np.minimum(center_y, 120 - center_y)\n",
    "    )\n",
    "    X['wall_d'] = wall_dist\n",
    "    X['wall_d30'] = wall_dist.rolling(30, min_periods=5).mean()\n",
    "\n",
    "    del grid_x, grid_y, wall_dist\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_advanced_temporal_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "    \n",
    "    for window in [10, 20, 40]:\n",
    "        X[f'speed_accel_{window}'] = speed.diff().rolling(window, min_periods=5).mean()\n",
    "        X[f'speed_jerk_{window}'] = speed.diff().diff().rolling(window, min_periods=5).mean()\n",
    "    \n",
    "    for window in [30, 60]:\n",
    "        X[f'speed_skew_{window}'] = speed.rolling(window, min_periods=10).skew()\n",
    "        X[f'speed_kurt_{window}'] = speed.rolling(window, min_periods=10).kurt()\n",
    "    \n",
    "    del speed\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_posture_features(X, single_mouse):\n",
    "    if all(p in single_mouse.columns for p in ['nose', 'body_center', 'tail_base', 'ear_left', 'ear_right']):\n",
    "        head_width = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "                            (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
    "        body_length = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "                             (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
    "        \n",
    "        X['aspect_ratio'] = body_length / (head_width + 1e-6)\n",
    "        \n",
    "        for window in [15, 30, 60]:\n",
    "            X[f'aspect_m{window}'] = X['aspect_ratio'].rolling(window, min_periods=5).mean()\n",
    "            X[f'aspect_s{window}'] = X['aspect_ratio'].rolling(window, min_periods=5).std()\n",
    "        \n",
    "        del head_width, body_length\n",
    "        gc.collect()\n",
    "    \n",
    "    return X\n",
    "\n",
    "def add_behavioral_rhythm_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "    \n",
    "    for window in [90, 180]:\n",
    "        if len(speed) >= window:\n",
    "            fft_vals = speed.rolling(window, min_periods=window//2).apply(\n",
    "                lambda x: np.abs(np.fft.rfft(x - x.mean())[1:6]).max() if len(x) >= 10 else 0, raw=True\n",
    "            )\n",
    "            X[f'rhythm_peak_{window}'] = fft_vals\n",
    "    \n",
    "    for window in [60, 120]:\n",
    "        active = (speed > speed.quantile(0.6)).astype(float)\n",
    "        X[f'active_ratio_{window}'] = active.rolling(window, min_periods=10).mean()\n",
    "        del active\n",
    "        gc.collect()\n",
    "    \n",
    "    del speed\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_pair_synchrony_features(X, mouse_pair, avail_A, avail_B):\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "    \n",
    "    A_speed = np.sqrt(mouse_pair['A']['body_center']['x'].diff()**2 + \n",
    "                     mouse_pair['A']['body_center']['y'].diff()**2)\n",
    "    B_speed = np.sqrt(mouse_pair['B']['body_center']['x'].diff()**2 + \n",
    "                     mouse_pair['B']['body_center']['y'].diff()**2)\n",
    "    \n",
    "    for window in [30, 60, 120]:\n",
    "        A_norm = (A_speed - A_speed.rolling(window, min_periods=10).mean()) / (A_speed.rolling(window, min_periods=10).std() + 1e-6)\n",
    "        B_norm = (B_speed - B_speed.rolling(window, min_periods=10).mean()) / (B_speed.rolling(window, min_periods=10).std() + 1e-6)\n",
    "        X[f'sync_{window}'] = (A_norm * B_norm).rolling(window, min_periods=10).mean()\n",
    "        del A_norm, B_norm\n",
    "        gc.collect()\n",
    "    \n",
    "    for window in [30, 60]:\n",
    "        A_active = (A_speed > A_speed.quantile(0.6)).astype(float)\n",
    "        B_active = (B_speed > B_speed.quantile(0.6)).astype(float)\n",
    "        X[f'co_active_{window}'] = (A_active * B_active).rolling(window, min_periods=5).mean()\n",
    "        del A_active, B_active\n",
    "        gc.collect()\n",
    "    \n",
    "    speed_diff = np.abs(A_speed - B_speed)\n",
    "    for window in [30, 60]:\n",
    "        X[f'speed_diff_m{window}'] = speed_diff.rolling(window, min_periods=5).mean()\n",
    "        X[f'speed_diff_s{window}'] = speed_diff.rolling(window, min_periods=5).std()\n",
    "    \n",
    "    del A_speed, B_speed, speed_diff\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_spatial_context_features(X, center_x, center_y):\n",
    "    for window in [60, 120, 240]:\n",
    "        if len(center_x) >= window:\n",
    "            X[f'area_covered_{window}'] = (center_x.rolling(window, min_periods=10).max() - center_x.rolling(window, min_periods=10).min()) * \\\n",
    "                                          (center_y.rolling(window, min_periods=10).max() - center_y.rolling(window, min_periods=10).min())\n",
    "    \n",
    "    arena_center_x = 60.0\n",
    "    arena_center_y = 60.0\n",
    "    dist_to_arena_center = np.sqrt((center_x - arena_center_x)**2 + (center_y - arena_center_y)**2)\n",
    "    \n",
    "    for window in [30, 60, 120]:\n",
    "        X[f'center_pref_{window}'] = (dist_to_arena_center < 30).astype(float).rolling(window, min_periods=5).mean()\n",
    "    \n",
    "    del dist_to_arena_center\n",
    "    gc.collect()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52967976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:36.227919Z",
     "iopub.status.busy": "2025-11-05T15:39:36.227626Z",
     "iopub.status.idle": "2025-11-05T15:39:36.238776Z",
     "shell.execute_reply": "2025-11-05T15:39:36.238287Z"
    },
    "papermill": {
     "duration": 0.015231,
     "end_time": "2025-11-05T15:39:36.239756",
     "exception": false,
     "start_time": "2025-11-05T15:39:36.224525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_momentum_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "    accel = speed.diff()\n",
    "    \n",
    "    for window in [10, 20, 40, 80]:\n",
    "        momentum = speed.rolling(window, min_periods=5).mean() * accel.rolling(window, min_periods=5).mean()\n",
    "        X[f'momentum_{window}'] = momentum\n",
    "        \n",
    "        speed_ewm = speed.ewm(span=window, min_periods=5).mean()\n",
    "        X[f'speed_momentum_{window}'] = speed_ewm * accel\n",
    "        \n",
    "        del momentum, speed_ewm\n",
    "        gc.collect()\n",
    "    \n",
    "    del speed, accel\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_directional_features(X, center_x, center_y):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    \n",
    "    direction = np.arctan2(vel_y, vel_x)\n",
    "    direction_change = direction.diff()\n",
    "    \n",
    "    for window in [15, 30, 60, 120]:\n",
    "        X[f'dir_std_{window}'] = direction.rolling(window, min_periods=5).std()\n",
    "        X[f'dir_range_{window}'] = direction.rolling(window, min_periods=5).max() - direction.rolling(window, min_periods=5).min()\n",
    "        X[f'dir_change_sum_{window}'] = np.abs(direction_change).rolling(window, min_periods=5).sum()\n",
    "        \n",
    "    persistence = (direction.diff().abs() < 0.1).astype(float)\n",
    "    for window in [30, 60]:\n",
    "        X[f'dir_persist_{window}'] = persistence.rolling(window, min_periods=5).mean()\n",
    "    \n",
    "    del vel_x, vel_y, direction, direction_change, persistence\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_acceleration_patterns(X, center_x, center_y):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    acc_x = vel_x.diff()\n",
    "    acc_y = vel_y.diff()\n",
    "    \n",
    "    acc_mag = np.sqrt(acc_x**2 + acc_y**2)\n",
    "    \n",
    "    for window in [10, 20, 40]:\n",
    "        X[f'acc_mean_{window}'] = acc_mag.rolling(window, min_periods=5).mean()\n",
    "        X[f'acc_std_{window}'] = acc_mag.rolling(window, min_periods=5).std()\n",
    "        X[f'acc_max_{window}'] = acc_mag.rolling(window, min_periods=5).max()\n",
    "        \n",
    "        burst = (acc_mag > acc_mag.quantile(0.75)).astype(float)\n",
    "        X[f'acc_burst_{window}'] = burst.rolling(window, min_periods=5).sum()\n",
    "        del burst\n",
    "        gc.collect()\n",
    "    \n",
    "    del vel_x, vel_y, acc_x, acc_y, acc_mag\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_relative_motion_features(X, mouse_pair, avail_A, avail_B):\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "    \n",
    "    A_vel_x = mouse_pair['A']['body_center']['x'].diff()\n",
    "    A_vel_y = mouse_pair['A']['body_center']['y'].diff()\n",
    "    B_vel_x = mouse_pair['B']['body_center']['x'].diff()\n",
    "    B_vel_y = mouse_pair['B']['body_center']['y'].diff()\n",
    "    \n",
    "    A_speed = np.sqrt(A_vel_x**2 + A_vel_y**2)\n",
    "    B_speed = np.sqrt(B_vel_x**2 + B_vel_y**2)\n",
    "    \n",
    "    rel_vel_x = A_vel_x - B_vel_x\n",
    "    rel_vel_y = A_vel_y - B_vel_y\n",
    "    rel_speed = np.sqrt(rel_vel_x**2 + rel_vel_y**2)\n",
    "    \n",
    "    for window in [15, 30, 60]:\n",
    "        X[f'rel_speed_m_{window}'] = rel_speed.rolling(window, min_periods=5).mean()\n",
    "        X[f'rel_speed_s_{window}'] = rel_speed.rolling(window, min_periods=5).std()\n",
    "        \n",
    "        speed_correlation = (A_speed * B_speed).rolling(window, min_periods=5).mean()\n",
    "        X[f'speed_corr_{window}'] = speed_correlation / (A_speed.rolling(window, min_periods=5).std() * B_speed.rolling(window, min_periods=5).std() + 1e-6)\n",
    "        \n",
    "        del speed_correlation\n",
    "        gc.collect()\n",
    "    \n",
    "    del A_vel_x, A_vel_y, B_vel_x, B_vel_y, A_speed, B_speed, rel_vel_x, rel_vel_y, rel_speed\n",
    "    gc.collect()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edf0c534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:36.245898Z",
     "iopub.status.busy": "2025-11-05T15:39:36.245695Z",
     "iopub.status.idle": "2025-11-05T15:39:36.287037Z",
     "shell.execute_reply": "2025-11-05T15:39:36.286472Z"
    },
    "papermill": {
     "duration": 0.045906,
     "end_time": "2025-11-05T15:39:36.288243",
     "exception": false,
     "start_time": "2025-11-05T15:39:36.242337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_single(single_mouse, body_parts_tracked):\n",
    "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"{p1}+{p2}\": np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n",
    "        if p1 in available_body_parts and p2 in available_body_parts\n",
    "    }, dtype=np.float32)\n",
    "    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n",
    "\n",
    "    if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n",
    "        for shift in [5, 10, 20]:\n",
    "            shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(shift)\n",
    "            speeds = pd.DataFrame({\n",
    "                f'sp_lf{shift}': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n",
    "                f'sp_rt{shift}': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
    "                f'sp_tb{shift}': np.square(single_mouse['tail_base'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "            }, dtype=np.float32)\n",
    "            X = pd.concat([X, speeds], axis=1)\n",
    "            del shifted, speeds\n",
    "            gc.collect()\n",
    "\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "        X['elong_inv'] = X['ear_left+ear_right'] / (X['nose+tail_base'] + 1e-6)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "        v1 = single_mouse['nose'] - single_mouse['body_center']\n",
    "        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
    "        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n",
    "            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n",
    "\n",
    "        for window in [15, 30, 60, 120]:\n",
    "            X[f'body_ang_m{window}'] = X['body_ang'].rolling(window, min_periods=5).mean()\n",
    "            X[f'body_ang_s{window}'] = X['body_ang'].rolling(window, min_periods=5).std()\n",
    "\n",
    "        del v1, v2\n",
    "        gc.collect()\n",
    "\n",
    "    if 'body_center' in available_body_parts:\n",
    "        cx = single_mouse['body_center']['x']\n",
    "        cy = single_mouse['body_center']['y']\n",
    "\n",
    "        for w in [5, 10, 15, 30, 60, 120]:\n",
    "            X[f'cx_m{w}'] = cx.rolling(w, min_periods=1, center=True).mean()\n",
    "            X[f'cy_m{w}'] = cy.rolling(w, min_periods=1, center=True).mean()\n",
    "            X[f'cx_s{w}'] = cx.rolling(w, min_periods=1, center=True).std()\n",
    "            X[f'cy_s{w}'] = cy.rolling(w, min_periods=1, center=True).std()\n",
    "            X[f'x_rng{w}'] = cx.rolling(w, min_periods=1, center=True).max() - cx.rolling(w, min_periods=1, center=True).min()\n",
    "            X[f'y_rng{w}'] = cy.rolling(w, min_periods=1, center=True).max() - cy.rolling(w, min_periods=1, center=True).min()\n",
    "            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(w, min_periods=1).sum()**2 + cy.diff().rolling(w, min_periods=1).sum()**2)\n",
    "            X[f'act{w}'] = np.sqrt(cx.diff().rolling(w, min_periods=1).var() + cy.diff().rolling(w, min_periods=1).var())\n",
    "\n",
    "        X = add_curvature_features(X, cx, cy)\n",
    "        X = add_multiscale_features(X, cx, cy)\n",
    "        X = add_state_features(X, cx, cy)\n",
    "        X = add_longrange_features(X, cx, cy)\n",
    "        X = add_spatial_features(X, cx, cy)\n",
    "        X = add_spectral_features(X, cx, cy)\n",
    "        X = add_advanced_temporal_features(X, cx, cy)\n",
    "        X = add_posture_features(X, single_mouse)\n",
    "        X = add_behavioral_rhythm_features(X, cx, cy)\n",
    "        X = add_spatial_context_features(X, cx, cy)\n",
    "        X = add_momentum_features(X, cx, cy)\n",
    "        X = add_directional_features(X, cx, cy)\n",
    "        X = add_acceleration_patterns(X, cx, cy)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n",
    "        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "                         (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
    "\n",
    "        for lag in [5, 10, 20, 40, 80]:\n",
    "            X[f'nt_lg{lag}'] = nt_dist.shift(lag)\n",
    "            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(lag)\n",
    "\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'nt_m{window}'] = nt_dist.rolling(window, min_periods=5).mean()\n",
    "            X[f'nt_s{window}'] = nt_dist.rolling(window, min_periods=5).std()\n",
    "            X[f'nt_mx{window}'] = nt_dist.rolling(window, min_periods=5).max()\n",
    "\n",
    "        del nt_dist\n",
    "        gc.collect()\n",
    "\n",
    "    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n",
    "        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "                       (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
    "\n",
    "        for off in [-40, -20, -10, 10, 20, 40]:\n",
    "            X[f'ear_o{off}'] = ear_d.shift(-off)\n",
    "\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'ear_m{window}'] = ear_d.rolling(window, min_periods=1, center=True).mean()\n",
    "            X[f'ear_s{window}'] = ear_d.rolling(window, min_periods=1, center=True).std()\n",
    "\n",
    "        X['ear_con'] = ear_d.rolling(30, min_periods=1, center=True).std() / (ear_d.rolling(30, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "        del ear_d\n",
    "        gc.collect()\n",
    "\n",
    "    if 'nose' in available_body_parts:\n",
    "        nose_speed = np.sqrt(single_mouse['nose']['x'].diff()**2 + single_mouse['nose']['y'].diff()**2)\n",
    "        for window in [15, 30, 60, 120]:\n",
    "            X[f'nose_sp{window}'] = nose_speed.rolling(window, min_periods=5).mean()\n",
    "            X[f'nose_sp_s{window}'] = nose_speed.rolling(window, min_periods=5).std()\n",
    "        del nose_speed\n",
    "        gc.collect()\n",
    "\n",
    "    if 'tail_base' in available_body_parts:\n",
    "        tail_speed = np.sqrt(single_mouse['tail_base']['x'].diff()**2 + single_mouse['tail_base']['y'].diff()**2)\n",
    "        for window in [15, 30, 60, 120]:\n",
    "            X[f'tail_sp{window}'] = tail_speed.rolling(window, min_periods=5).mean()\n",
    "            X[f'tail_sp_s{window}'] = tail_speed.rolling(window, min_periods=5).std()\n",
    "        del tail_speed\n",
    "        gc.collect()\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def transform_pair(mouse_pair, body_parts_tracked):\n",
    "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
    "        if p1 in avail_A and p2 in avail_B\n",
    "    }, dtype=np.float32)\n",
    "    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n",
    "\n",
    "    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "        for shift in [5, 10, 20]:\n",
    "            shA = mouse_pair['A']['ear_left'].shift(shift)\n",
    "            shB = mouse_pair['B']['ear_left'].shift(shift)\n",
    "            speeds = pd.DataFrame({\n",
    "                f'sp_A{shift}': np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n",
    "                f'sp_AB{shift}': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "                f'sp_B{shift}': np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "            }, dtype=np.float32)\n",
    "            X = pd.concat([X, speeds], axis=1)\n",
    "            del shA, shB, speeds\n",
    "            gc.collect()\n",
    "\n",
    "    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
    "        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
    "        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
    "        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n",
    "            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n",
    "\n",
    "        for window in [15, 30, 60, 120]:\n",
    "            X[f'rel_ori_m{window}'] = X['rel_ori'].rolling(window, min_periods=5).mean()\n",
    "            X[f'rel_ori_s{window}'] = X['rel_ori'].rolling(window, min_periods=5).std()\n",
    "\n",
    "        del dir_A, dir_B\n",
    "        gc.collect()\n",
    "\n",
    "    if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n",
    "        cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
    "\n",
    "        for lag in [5, 10, 20, 40, 80]:\n",
    "            shA_n = mouse_pair['A']['nose'].shift(lag)\n",
    "            shB_n = mouse_pair['B']['nose'].shift(lag)\n",
    "            past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
    "            X[f'appr{lag}'] = cur - past\n",
    "            del shA_n, shB_n, past\n",
    "            gc.collect()\n",
    "\n",
    "        del cur\n",
    "        gc.collect()\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                    (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "\n",
    "        X['v_cls'] = (cd < 5.0).astype(np.float32)\n",
    "        X['cls'] = ((cd >= 5.0) & (cd < 15.0)).astype(np.float32)\n",
    "        X['med'] = ((cd >= 15.0) & (cd < 30.0)).astype(np.float32)\n",
    "        X['far'] = (cd >= 30.0).astype(np.float32)\n",
    "\n",
    "        for window in [30, 60, 120, 240]:\n",
    "            X[f'v_cls_m{window}'] = X['v_cls'].rolling(window, min_periods=5).mean()\n",
    "            X[f'cls_m{window}'] = X['cls'].rolling(window, min_periods=5).mean()\n",
    "            X[f'med_m{window}'] = X['med'].rolling(window, min_periods=5).mean()\n",
    "\n",
    "        cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
    "\n",
    "        for w in [5, 10, 15, 30, 60, 120, 240]:\n",
    "            X[f'd_m{w}'] = cd_full.rolling(w, min_periods=1, center=True).mean()\n",
    "            X[f'd_s{w}'] = cd_full.rolling(w, min_periods=1, center=True).std()\n",
    "            X[f'd_mn{w}'] = cd_full.rolling(w, min_periods=1, center=True).min()\n",
    "            X[f'd_mx{w}'] = cd_full.rolling(w, min_periods=1, center=True).max()\n",
    "\n",
    "            d_var = cd_full.rolling(w, min_periods=1, center=True).var()\n",
    "            X[f'int{w}'] = 1 / (1 + d_var)\n",
    "            del d_var\n",
    "            gc.collect()\n",
    "\n",
    "        Axd = mouse_pair['A']['body_center']['x'].diff()\n",
    "        Ayd = mouse_pair['A']['body_center']['y'].diff()\n",
    "        Bxd = mouse_pair['B']['body_center']['x'].diff()\n",
    "        Byd = mouse_pair['B']['body_center']['y'].diff()\n",
    "\n",
    "        for w in [5, 10, 15, 30, 60, 120]:\n",
    "            coord = Axd * Bxd + Ayd * Byd\n",
    "            X[f'co_m{w}'] = coord.rolling(w, min_periods=1, center=True).mean()\n",
    "            X[f'co_s{w}'] = coord.rolling(w, min_periods=1, center=True).std()\n",
    "            del coord\n",
    "            gc.collect()\n",
    "\n",
    "        cd_change = cd.diff()\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'cd_ch{window}'] = cd_change.rolling(window, min_periods=5).sum()\n",
    "            X[f'cd_ch_s{window}'] = cd_change.rolling(window, min_periods=5).std()\n",
    "\n",
    "        val = (Axd * Bxd + Ayd * Byd) / (np.sqrt(Axd**2 + Ayd**2) * np.sqrt(Bxd**2 + Byd**2) + 1e-6)\n",
    "\n",
    "        for off in [-40, -20, -10, 0, 10, 20, 40]:\n",
    "            X[f'va_{off}'] = val.shift(-off)\n",
    "\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'va_m{window}'] = val.rolling(window, min_periods=5).mean()\n",
    "            X[f'va_s{window}'] = val.rolling(window, min_periods=5).std()\n",
    "\n",
    "        A_speed = np.sqrt(Axd**2 + Ayd**2)\n",
    "        B_speed = np.sqrt(Bxd**2 + Byd**2)\n",
    "        X['speed_ratio'] = A_speed / (B_speed + 1e-6)\n",
    "        X['speed_diff'] = A_speed - B_speed\n",
    "\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'A_sp{window}'] = A_speed.rolling(window, min_periods=5).mean()\n",
    "            X[f'B_sp{window}'] = B_speed.rolling(window, min_periods=5).mean()\n",
    "            X[f'sp_rat{window}'] = (A_speed / (B_speed + 1e-6)).rolling(window, min_periods=5).mean()\n",
    "\n",
    "        X = add_interaction_features(X, mouse_pair, avail_A, avail_B)\n",
    "        X = add_pair_synchrony_features(X, mouse_pair, avail_A, avail_B)\n",
    "        X = add_relative_motion_features(X, mouse_pair, avail_A, avail_B)\n",
    "\n",
    "        del cd, cd_full, cd_change, Axd, Ayd, Bxd, Byd, val, A_speed, B_speed\n",
    "        gc.collect()\n",
    "\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "                    (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
    "\n",
    "        for lag in [5, 10, 20, 40, 80]:\n",
    "            X[f'nn_lg{lag}'] = nn.shift(lag)\n",
    "            X[f'nn_ch{lag}'] = nn - nn.shift(lag)\n",
    "\n",
    "            is_cl = (nn < 10.0).astype(np.float32)\n",
    "            X[f'cl_ps{lag}'] = is_cl.rolling(lag, min_periods=1).mean()\n",
    "            del is_cl\n",
    "            gc.collect()\n",
    "\n",
    "        for window in [30, 60, 120, 240]:\n",
    "            X[f'nn_m{window}'] = nn.rolling(window, min_periods=5).mean()\n",
    "            X[f'nn_s{window}'] = nn.rolling(window, min_periods=5).std()\n",
    "            X[f'nn_mn{window}'] = nn.rolling(window, min_periods=5).min()\n",
    "\n",
    "        del nn\n",
    "        gc.collect()\n",
    "\n",
    "    if 'nose' in avail_A and 'body_center' in avail_B:\n",
    "        nose_to_body = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                               (mouse_pair['A']['nose']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'nb_m{window}'] = nose_to_body.rolling(window, min_periods=5).mean()\n",
    "            X[f'nb_s{window}'] = nose_to_body.rolling(window, min_periods=5).std()\n",
    "        del nose_to_body\n",
    "        gc.collect()\n",
    "\n",
    "    if 'body_center' in avail_A and 'nose' in avail_B:\n",
    "        body_to_nose = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "                               (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'bn_m{window}'] = body_to_nose.rolling(window, min_periods=5).mean()\n",
    "            X[f'bn_s{window}'] = body_to_nose.rolling(window, min_periods=5).std()\n",
    "        del body_to_nose\n",
    "        gc.collect()\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    gc.collect()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2267d938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:36.297732Z",
     "iopub.status.busy": "2025-11-05T15:39:36.297495Z",
     "iopub.status.idle": "2025-11-05T15:39:36.304533Z",
     "shell.execute_reply": "2025-11-05T15:39:36.303954Z"
    },
    "papermill": {
     "duration": 0.012006,
     "end_time": "2025-11-05T15:39:36.305521",
     "exception": false,
     "start_time": "2025-11-05T15:39:36.293515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_cat_model_2(X_tr, label, base_subsample):\n",
    "    model = make_pipeline(\n",
    "        SimpleImputer(strategy='median'),\n",
    "        StratifiedSubsetClassifier(\n",
    "            CatBoostClassifier(\n",
    "                iterations=280,\n",
    "                learning_rate=0.05,\n",
    "                depth=10,\n",
    "                l2_leaf_reg=3.5,\n",
    "                random_strength=0.6,\n",
    "                bagging_temperature=0.8,\n",
    "                task_type='GPU',\n",
    "                verbose=False,\n",
    "                allow_writing_files=False,\n",
    "                random_seed=SEED + 1\n",
    "            ),\n",
    "            base_subsample,\n",
    "            random_state=SEED + 1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    model_list = []\n",
    "    action_counter = 0\n",
    "\n",
    "    for action in label.columns:\n",
    "        action_mask = ~ label[action].isna().values\n",
    "        y_action = label[action][action_mask].values.astype(np.int8)\n",
    "\n",
    "        if not (y_action == 0).all() and y_action.sum() >= 5:\n",
    "            m_clone = clone(model)\n",
    "            m_clone.fit(X_tr[action_mask], y_action)\n",
    "            model_list.append((action, m_clone))\n",
    "            action_counter += 1\n",
    "\n",
    "            if action_counter % 2 == 0:\n",
    "                mem_current = psutil.virtual_memory().percent\n",
    "                print(f\"    Trained {action_counter} actions, Memory: {mem_current}%\")\n",
    "                gc.collect()\n",
    "                if CUPY_AVAILABLE:\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "            del y_action, m_clone\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bdbde0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T15:39:36.311572Z",
     "iopub.status.busy": "2025-11-05T15:39:36.311369Z",
     "iopub.status.idle": "2025-11-05T16:50:25.755995Z",
     "shell.execute_reply": "2025-11-05T16:50:25.755090Z"
    },
    "papermill": {
     "duration": 4249.449414,
     "end_time": "2025-11-05T16:50:25.757502",
     "exception": false,
     "start_time": "2025-11-05T15:39:36.308088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Model 2 Training\n",
      "Starting Memory: 4.4%\n",
      "\n",
      "1. Processing: 18 body parts\n",
      "  Single: (544859, 295)\n",
      "  Data size: 544,859 rows\n",
      "  Pair: (1524906, 288)\n",
      "  Data size: 1,524,906 rows\n",
      "    Trained 2 actions, Memory: 19.5%\n",
      "    Trained 4 actions, Memory: 19.6%\n",
      "    Trained 6 actions, Memory: 19.5%\n",
      "  Section 1 complete. Memory: 7.9%\n",
      "\n",
      "2. Processing: 14 body parts\n",
      "  Single: (478728, 304)\n",
      "  Data size: 478,728 rows\n",
      "  Pair: (613716, 307)\n",
      "  Data size: 613,716 rows\n",
      "    Trained 2 actions, Memory: 11.6%\n",
      "  Section 2 complete. Memory: 7.1%\n",
      "\n",
      "3. Processing: 10 body parts\n",
      "  Single: (1941885, 295)\n",
      "  Data size: 1,941,885 rows\n",
      "  Pair: (5607030, 288)\n",
      "  Data size: 5,607,030 rows\n",
      "  Downsampled to: 2,000,000 rows (ratio: 35.67%)\n",
      "    Trained 2 actions, Memory: 22.8%\n",
      "    Trained 4 actions, Memory: 22.8%\n",
      "    Trained 6 actions, Memory: 22.9%\n",
      "  Section 3 complete. Memory: 16.0%\n",
      "\n",
      "4. Processing: 8 body parts\n",
      "  Pair: (2210177, 271)\n",
      "  Data size: 2,210,177 rows\n",
      "    Trained 2 actions, Memory: 24.6%\n",
      "    Trained 4 actions, Memory: 29.2%\n",
      "    Trained 6 actions, Memory: 29.2%\n",
      "  Section 4 complete. Memory: 13.5%\n",
      "\n",
      "5. Processing: 7 body parts\n",
      "No labeled behaviors: SparklingTapir 139713291\n",
      "No labeled behaviors: SparklingTapir 167444193\n",
      "No labeled behaviors: SparklingTapir 329031399\n",
      "No labeled behaviors: SparklingTapir 361341393\n",
      "No labeled behaviors: SparklingTapir 484405601\n",
      "No labeled behaviors: SparklingTapir 610412175\n",
      "No labeled behaviors: SparklingTapir 687999061\n",
      "No labeled behaviors: SparklingTapir 801328824\n",
      "No labeled behaviors: SparklingTapir 834408298\n",
      "No labeled behaviors: SparklingTapir 1085312517\n",
      "No labeled behaviors: SparklingTapir 1366115611\n",
      "No labeled behaviors: SparklingTapir 1430299100\n",
      "No labeled behaviors: SparklingTapir 1543851393\n",
      "No labeled behaviors: SparklingTapir 1588709555\n",
      "No labeled behaviors: SparklingTapir 1772737271\n",
      "  Pair: (960574, 256)\n",
      "  Data size: 960,574 rows\n",
      "    Trained 2 actions, Memory: 14.0%\n",
      "    Trained 4 actions, Memory: 13.9%\n",
      "  Section 5 complete. Memory: 8.5%\n",
      "\n",
      "6. Processing: 5 body parts\n",
      "  Single: (708496, 269)\n",
      "  Data size: 708,496 rows\n",
      "    Trained 2 actions, Memory: 18.1%\n",
      "    Trained 4 actions, Memory: 18.1%\n",
      "    Trained 6 actions, Memory: 18.2%\n",
      "  Pair: (10212910, 232)\n",
      "  Data size: 10,212,910 rows\n",
      "  Downsampled to: 2,000,000 rows (ratio: 19.58%)\n",
      "    Trained 2 actions, Memory: 15.4%\n",
      "    Trained 4 actions, Memory: 15.3%\n",
      "    Trained 6 actions, Memory: 15.4%\n",
      "    Trained 8 actions, Memory: 15.4%\n",
      "    Trained 10 actions, Memory: 15.5%\n",
      "    Trained 12 actions, Memory: 15.5%\n",
      "  Section 6 complete. Memory: 10.0%\n",
      "\n",
      "7. Processing: 4 body parts\n",
      "  Single: (899134, 36)\n",
      "  Data size: 899,134 rows\n",
      "    Trained 2 actions, Memory: 9.3%\n",
      "    Trained 4 actions, Memory: 9.3%\n",
      "    Trained 6 actions, Memory: 9.3%\n",
      "  Pair: (899134, 25)\n",
      "  Data size: 899,134 rows\n",
      "    Trained 2 actions, Memory: 9.3%\n",
      "    Trained 4 actions, Memory: 9.4%\n",
      "    Trained 6 actions, Memory: 9.3%\n",
      "  Section 7 complete. Memory: 9.3%\n",
      "\n",
      "8. Processing: 7 body parts\n",
      "  Single: (3020371, 80)\n",
      "  Data size: 3,020,371 rows\n",
      "  Downsampled to: 2,000,000 rows (ratio: 66.22%)\n",
      "    Trained 2 actions, Memory: 18.7%\n",
      "    Trained 4 actions, Memory: 17.2%\n",
      "  Pair: (12259207, 99)\n",
      "  Data size: 12,259,207 rows\n",
      "  Downsampled to: 2,000,000 rows (ratio: 16.31%)\n",
      "    Trained 2 actions, Memory: 17.0%\n",
      "    Trained 4 actions, Memory: 17.1%\n",
      "    Trained 6 actions, Memory: 18.8%\n",
      "    Trained 8 actions, Memory: 17.0%\n",
      "    Trained 10 actions, Memory: 17.0%\n",
      "    Trained 12 actions, Memory: 17.0%\n",
      "    Trained 14 actions, Memory: 17.0%\n",
      "    Trained 16 actions, Memory: 17.0%\n",
      "  Section 8 complete. Memory: 14.3%\n",
      "\n",
      "9. Processing: 5 body parts\n",
      "  Single: (329777, 69)\n",
      "  Data size: 329,777 rows\n",
      "    Trained 2 actions, Memory: 13.6%\n",
      "  Pair: (1700260, 75)\n",
      "  Data size: 1,700,260 rows\n",
      "    Trained 2 actions, Memory: 14.2%\n",
      "    Trained 4 actions, Memory: 14.2%\n",
      "  Section 9 complete. Memory: 13.6%\n",
      "\n",
      "\n",
      "CatBoost Model 2 Training Complete\n",
      "Final Memory: 13.6%\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('/kaggle/working/models', exist_ok=True)\n",
    "\n",
    "print(f\"Starting CatBoost Model 2 Training\")\n",
    "print(f\"Starting Memory: {psutil.virtual_memory().percent}%\\n\")\n",
    "\n",
    "for section in range(1, len(body_parts_tracked_list)):\n",
    "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "    try:\n",
    "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "        print(f\"{section}. Processing: {len(body_parts_tracked)} body parts\")\n",
    "        if len(body_parts_tracked) > 5:\n",
    "            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "        single_list, single_label_list, single_meta_list = [], [], []\n",
    "        pair_list, pair_label_list, pair_meta_list = [], [], []\n",
    "\n",
    "        for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n",
    "            if switch == 'single':\n",
    "                single_list.append(data)\n",
    "                single_meta_list.append(meta)\n",
    "                single_label_list.append(label)\n",
    "            else:\n",
    "                pair_list.append(data)\n",
    "                pair_meta_list.append(meta)\n",
    "                pair_label_list.append(label)\n",
    "\n",
    "        if len(single_list) > 0:\n",
    "            single_mouse = pd.concat(single_list)\n",
    "            single_label = pd.concat(single_label_list)\n",
    "            single_meta = pd.concat(single_meta_list)\n",
    "            del single_list, single_label_list, single_meta_list\n",
    "            gc.collect()\n",
    "            if CUPY_AVAILABLE:\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "            X_tr = transform_single(single_mouse, body_parts_tracked)\n",
    "            del single_mouse\n",
    "            gc.collect()\n",
    "\n",
    "            print(f\"  Single: {X_tr.shape}\")\n",
    "            \n",
    "            data_size = len(X_tr)\n",
    "            print(f\"  Data size: {data_size:,} rows\")\n",
    "\n",
    "            if data_size > 2500000:\n",
    "                max_samples = 2000000\n",
    "                np.random.seed(SEED)\n",
    "                sample_idx = np.random.choice(data_size, min(max_samples, data_size), replace=False)\n",
    "                sample_idx = np.sort(sample_idx)\n",
    "    \n",
    "                X_tr = X_tr.iloc[sample_idx].reset_index(drop=True)\n",
    "                single_label = single_label.iloc[sample_idx].reset_index(drop=True)\n",
    "                single_meta = single_meta.iloc[sample_idx].reset_index(drop=True)\n",
    "    \n",
    "                print(f\"  Downsampled to: {len(X_tr):,} rows (ratio: {len(X_tr)/data_size:.2%})\")\n",
    "                del sample_idx\n",
    "                gc.collect()\n",
    "\n",
    "            base_subsample = 1200000 if data_size > 2000000 else 1500000\n",
    "            model_list = train_cat_model_2(X_tr, single_label, base_subsample)\n",
    "            \n",
    "            with open(f'/kaggle/working/models/cat2_single_{section}.pkl', 'wb') as f:\n",
    "                pickle.dump(model_list, f)\n",
    "            \n",
    "            del X_tr, single_label, single_meta, model_list\n",
    "            gc.collect()\n",
    "            if CUPY_AVAILABLE:\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "        if len(pair_list) > 0:\n",
    "            mouse_pair = pd.concat(pair_list)\n",
    "            pair_label = pd.concat(pair_label_list)\n",
    "            pair_meta = pd.concat(pair_meta_list)\n",
    "            del pair_list, pair_label_list, pair_meta_list\n",
    "            gc.collect()\n",
    "            if CUPY_AVAILABLE:\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "            X_tr = transform_pair(mouse_pair, body_parts_tracked)\n",
    "            del mouse_pair\n",
    "            gc.collect()\n",
    "\n",
    "            print(f\"  Pair: {X_tr.shape}\")\n",
    "            \n",
    "            data_size = len(X_tr)\n",
    "            print(f\"  Data size: {data_size:,} rows\")\n",
    "\n",
    "            if data_size > 2500000:\n",
    "                max_samples = 2000000\n",
    "                np.random.seed(SEED)\n",
    "                sample_idx = np.random.choice(data_size, min(max_samples, data_size), replace=False)\n",
    "                sample_idx = np.sort(sample_idx)\n",
    "    \n",
    "                X_tr = X_tr.iloc[sample_idx].reset_index(drop=True)\n",
    "                pair_label = pair_label.iloc[sample_idx].reset_index(drop=True)\n",
    "                pair_meta = pair_meta.iloc[sample_idx].reset_index(drop=True)\n",
    "    \n",
    "                print(f\"  Downsampled to: {len(X_tr):,} rows (ratio: {len(X_tr)/data_size:.2%})\")\n",
    "                del sample_idx\n",
    "                gc.collect()\n",
    "\n",
    "            base_subsample = 1200000 if data_size > 2000000 else 1500000\n",
    "            model_list = train_cat_model_2(X_tr, pair_label, base_subsample)\n",
    "            \n",
    "            with open(f'/kaggle/working/models/cat2_pair_{section}.pkl', 'wb') as f:\n",
    "                pickle.dump(model_list, f)\n",
    "            \n",
    "            del X_tr, pair_label, pair_meta, model_list\n",
    "            gc.collect()\n",
    "            if CUPY_AVAILABLE:\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "        mem_current = psutil.virtual_memory().percent\n",
    "        print(f\"  Section {section} complete. Memory: {mem_current}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'***Exception*** {str(e)[:100]}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "    gc.collect()\n",
    "    if CUPY_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print()\n",
    "\n",
    "print(f\"\\nCatBoost Model 2 Training Complete\")\n",
    "print(f\"Final Memory: {psutil.virtual_memory().percent}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4260.108815,
   "end_time": "2025-11-05T16:50:26.586163",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-05T15:39:26.477348",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
