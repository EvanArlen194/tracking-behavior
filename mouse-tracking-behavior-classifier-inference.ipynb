{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14a75cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:09.104040Z",
     "iopub.status.busy": "2025-11-05T18:42:09.103772Z",
     "iopub.status.idle": "2025-11-05T18:42:18.553304Z",
     "shell.execute_reply": "2025-11-05T18:42:18.552226Z"
    },
    "papermill": {
     "duration": 9.455782,
     "end_time": "2025-11-05T18:42:18.554570",
     "exception": false,
     "start_time": "2025-11-05T18:42:09.098788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy available - GPU acceleration enabled\n",
      "Available RAM: 31.4 GB\n",
      "Current usage: 3.9%\n",
      "GPU Memory: 14.7 GB\n"
     ]
    }
   ],
   "source": [
    "validate_or_submit = 'submit'\n",
    "verbose = True\n",
    "SEED = 42\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import polars as pl\n",
    "from scipy import signal, stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import psutil\n",
    "import pickle\n",
    "\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator, clone\n",
    "from sklearn.model_selection import cross_val_predict, GroupKFold, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(SEED)\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    CUPY_AVAILABLE = True\n",
    "    print(\"CuPy available - GPU acceleration enabled\")\n",
    "except:\n",
    "    CUPY_AVAILABLE = False\n",
    "    print(\"CuPy not available - using CPU fallback\")\n",
    "\n",
    "print(f\"Available RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "print(f\"Current usage: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "if CUPY_AVAILABLE:\n",
    "    print(f\"GPU Memory: {cp.cuda.Device(0).mem_info[1] / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7d3f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:18.562460Z",
     "iopub.status.busy": "2025-11-05T18:42:18.561648Z",
     "iopub.status.idle": "2025-11-05T18:42:18.569619Z",
     "shell.execute_reply": "2025-11-05T18:42:18.568965Z"
    },
    "papermill": {
     "duration": 0.012762,
     "end_time": "2025-11-05T18:42:18.570830",
     "exception": false,
     "start_time": "2025-11-05T18:42:18.558068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StratifiedSubsetClassifier(ClassifierMixin, BaseEstimator):\n",
    "    def __init__(self, estimator, n_samples, random_state=42):\n",
    "        self.estimator = estimator\n",
    "        self.n_samples = n_samples\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if len(X) <= self.n_samples:\n",
    "            self.estimator.fit(X, y)\n",
    "        else:\n",
    "            from sklearn.model_selection import StratifiedShuffleSplit\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=min(self.n_samples, len(X)), random_state=self.random_state)\n",
    "            try:\n",
    "                for train_idx, _ in sss.split(X, y):\n",
    "                    X_sample = X.iloc[train_idx] if hasattr(X, 'iloc') else X[train_idx]\n",
    "                    y_sample = y[train_idx]\n",
    "                    self.estimator.fit(X_sample, y_sample)\n",
    "                    del X_sample, y_sample\n",
    "            except:\n",
    "                np.random.seed(self.random_state)\n",
    "                downsample = max(len(X) // self.n_samples, 1)\n",
    "                X_ds = X[::downsample]\n",
    "                y_ds = y[::downsample]\n",
    "                self.estimator.fit(X_ds, y_ds)\n",
    "                del X_ds, y_ds\n",
    "\n",
    "        self.classes_ = self.estimator.classes_\n",
    "        gc.collect()\n",
    "        if CUPY_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if len(self.classes_) == 1:\n",
    "            return np.full((len(X), 1), 1.0)\n",
    "        proba = self.estimator.predict_proba(X)\n",
    "        return proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = self.estimator.predict(X)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e3a609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:18.577748Z",
     "iopub.status.busy": "2025-11-05T18:42:18.577522Z",
     "iopub.status.idle": "2025-11-05T18:42:19.283825Z",
     "shell.execute_reply": "2025-11-05T18:42:19.282823Z"
    },
    "papermill": {
     "duration": 0.711277,
     "end_time": "2025-11-05T18:42:19.285151",
     "exception": false,
     "start_time": "2025-11-05T18:42:18.573874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory after loading: 4.4%\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/train.csv')\n",
    "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "train_without_mabe22 = train.query(\"~ lab_id.str.startswith('MABe22_')\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/test.csv')\n",
    "body_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n",
    "\n",
    "drop_body_parts = ['headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright',\n",
    "                   'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright',\n",
    "                   'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint']\n",
    "\n",
    "arena_metadata = {}\n",
    "for _, row in pd.concat([train, test]).iterrows():\n",
    "    arena_metadata[row['video_id']] = {\n",
    "        'pix_per_cm': row['pix_per_cm_approx'],\n",
    "        'fps': row.get('fps', 30),\n",
    "        'lab_id': row['lab_id']\n",
    "    }\n",
    "\n",
    "gc.collect()\n",
    "print(f\"Memory after loading: {psutil.virtual_memory().percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92e90f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:19.293772Z",
     "iopub.status.busy": "2025-11-05T18:42:19.293359Z",
     "iopub.status.idle": "2025-11-05T18:42:19.310859Z",
     "shell.execute_reply": "2025-11-05T18:42:19.310145Z"
    },
    "papermill": {
     "duration": 0.023516,
     "end_time": "2025-11-05T18:42:19.312303",
     "exception": false,
     "start_time": "2025-11-05T18:42:19.288787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_coordinates(x, y, pix_per_cm, arena_width_cm=120, arena_height_cm=120):\n",
    "    x_norm = np.clip(x / pix_per_cm, 0, arena_width_cm)\n",
    "    y_norm = np.clip(y / pix_per_cm, 0, arena_height_cm)\n",
    "    return x_norm, y_norm\n",
    "\n",
    "def generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n",
    "    assert traintest in ['train', 'test']\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "    for _, row in dataset.iterrows():\n",
    "\n",
    "        lab_id = row.lab_id\n",
    "        if lab_id.startswith('MABe22'):\n",
    "            continue\n",
    "        video_id = row.video_id\n",
    "\n",
    "        if type(row.behaviors_labeled) != str:\n",
    "            if verbose:\n",
    "                print('No labeled behaviors:', lab_id, video_id)\n",
    "            continue\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "\n",
    "        try:\n",
    "            vid = pd.read_parquet(path, columns=['video_frame', 'mouse_id', 'bodypart', 'x', 'y'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n",
    "\n",
    "        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n",
    "\n",
    "        if pvid.isna().any().any():\n",
    "            if verbose and traintest == 'test':\n",
    "                print('video with missing values', video_id, traintest, len(vid), 'frames')\n",
    "\n",
    "        del vid\n",
    "        gc.collect()\n",
    "\n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n",
    "        pvid = pvid.astype(np.float32)\n",
    "\n",
    "        for mouse_id in np.unique(pvid.columns.get_level_values('mouse_id')):\n",
    "            for bodypart_name in pvid[mouse_id].columns.get_level_values(0).unique():\n",
    "                if 'x' in pvid[mouse_id][bodypart_name].columns:\n",
    "                    x_vals = pvid[(mouse_id, bodypart_name, 'x')]\n",
    "                    y_vals = pvid[(mouse_id, bodypart_name, 'y')]\n",
    "                    x_norm, y_norm = normalize_coordinates(x_vals, y_vals, row.pix_per_cm_approx)\n",
    "                    pvid[(mouse_id, bodypart_name, 'x')] = x_norm\n",
    "                    pvid[(mouse_id, bodypart_name, 'y')] = y_norm\n",
    "\n",
    "        vid_behaviors = json.loads(row.behaviors_labeled)\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "\n",
    "        if traintest == 'train':\n",
    "            try:\n",
    "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
    "            except FileNotFoundError:\n",
    "                del pvid\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "        if generate_single:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\")\n",
    "            for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n",
    "                try:\n",
    "                    mouse_id = int(mouse_id_str[-1])\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n",
    "                    single_mouse = pvid.loc[:, mouse_id].copy()\n",
    "                    single_mouse_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': mouse_id_str,\n",
    "                        'target_id': 'self',\n",
    "                        'video_frame': single_mouse.index,\n",
    "                        'fps': row.get('fps', 30)\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index, dtype=np.float32)\n",
    "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print('- test single', video_id, mouse_id)\n",
    "                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "        if generate_pair:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n",
    "            if len(vid_behaviors_subset) > 0:\n",
    "                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2):\n",
    "                    agent_str = f\"mouse{agent}\"\n",
    "                    target_str = f\"mouse{target}\"\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
    "                    if len(vid_agent_actions) == 0:\n",
    "                        continue\n",
    "\n",
    "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B']).copy()\n",
    "                    mouse_pair_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': agent_str,\n",
    "                        'target_id': target_str,\n",
    "                        'video_frame': mouse_pair.index,\n",
    "                        'fps': row.get('fps', 30)\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index, dtype=np.float32)\n",
    "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print('- test pair', video_id, agent, target)\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions\n",
    "\n",
    "        del pvid\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0138cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:19.320811Z",
     "iopub.status.busy": "2025-11-05T18:42:19.320458Z",
     "iopub.status.idle": "2025-11-05T18:42:19.357919Z",
     "shell.execute_reply": "2025-11-05T18:42:19.356831Z"
    },
    "papermill": {
     "duration": 0.04323,
     "end_time": "2025-11-05T18:42:19.359104",
     "exception": false,
     "start_time": "2025-11-05T18:42:19.315874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_rolling(series, window, func, min_periods=None):\n",
    "    if min_periods is None:\n",
    "        min_periods = max(1, window // 4)\n",
    "    return series.rolling(window, min_periods=min_periods, center=True).apply(func, raw=True)\n",
    "\n",
    "def add_spectral_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "\n",
    "    for window in [60, 120]:\n",
    "        if len(speed) >= window:\n",
    "            speed_chunk = speed.rolling(window, min_periods=window//2).apply(\n",
    "                lambda x: np.sum(np.abs(np.fft.rfft(x - x.mean())[:5])), raw=True\n",
    "            )\n",
    "            X[f'fft_pwr{window}'] = speed_chunk\n",
    "\n",
    "    del speed\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_curvature_features(X, center_x, center_y):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    acc_x = vel_x.diff()\n",
    "    acc_y = vel_y.diff()\n",
    "\n",
    "    cross_prod = vel_x * acc_y - vel_y * acc_x\n",
    "    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n",
    "    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)\n",
    "\n",
    "    X['curv_m30'] = curvature.rolling(30, min_periods=5).mean()\n",
    "    X['curv_m60'] = curvature.rolling(60, min_periods=10).mean()\n",
    "    X['curv_s30'] = curvature.rolling(30, min_periods=5).std()\n",
    "    X['curv_max60'] = curvature.rolling(60, min_periods=10).max()\n",
    "\n",
    "    angle = np.arctan2(vel_y, vel_x)\n",
    "    angle_change = np.abs(angle.diff())\n",
    "    X['turn_r30'] = angle_change.rolling(30, min_periods=5).sum()\n",
    "    X['turn_r60'] = angle_change.rolling(60, min_periods=10).sum()\n",
    "    X['turn_m30'] = angle_change.rolling(30, min_periods=5).mean()\n",
    "    X['turn_std30'] = angle_change.rolling(30, min_periods=5).std()\n",
    "\n",
    "    del vel_x, vel_y, acc_x, acc_y, cross_prod, vel_mag, curvature, angle, angle_change\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_multiscale_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "\n",
    "    scales = [5, 10, 20, 40, 80, 160]\n",
    "    for scale in scales:\n",
    "        if len(speed) >= scale:\n",
    "            min_p = max(1, scale//4)\n",
    "            X[f'sp_m{scale}'] = speed.rolling(scale, min_periods=min_p).mean()\n",
    "            X[f'sp_s{scale}'] = speed.rolling(scale, min_periods=min_p).std()\n",
    "            X[f'sp_mx{scale}'] = speed.rolling(scale, min_periods=min_p).max()\n",
    "            X[f'sp_mn{scale}'] = speed.rolling(scale, min_periods=min_p).min()\n",
    "\n",
    "    if len(scales) >= 2:\n",
    "        for i in range(len(scales)-1):\n",
    "            if f'sp_m{scales[i]}' in X.columns and f'sp_m{scales[i+1]}' in X.columns:\n",
    "                X[f'sp_rt{scales[i]}_{scales[i+1]}'] = X[f'sp_m{scales[i]}'] / (X[f'sp_m{scales[i+1]}'] + 1e-6)\n",
    "\n",
    "    del speed\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_state_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "    speed_ma = speed.rolling(15, min_periods=5).mean()\n",
    "\n",
    "    try:\n",
    "        speed_states = pd.cut(speed_ma, bins=[-np.inf, 0.5, 2.0, 5.0, np.inf], labels=[0, 1, 2, 3]).astype(float)\n",
    "\n",
    "        for window in [30, 60, 120, 240]:\n",
    "            if len(speed_states) >= window:\n",
    "                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n",
    "                X[f'trans_{window}'] = state_changes.rolling(window, min_periods=10).sum()\n",
    "                X[f'state_m{window}'] = speed_states.rolling(window, min_periods=10).mean()\n",
    "                X[f'state_s{window}'] = speed_states.rolling(window, min_periods=10).std()\n",
    "\n",
    "        del speed_states, state_changes\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    del speed, speed_ma\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_longrange_features(X, center_x, center_y):\n",
    "    for window in [60, 120, 240]:\n",
    "        if len(center_x) >= window:\n",
    "            X[f'x_ml{window}'] = center_x.rolling(window, min_periods=20).mean()\n",
    "            X[f'y_ml{window}'] = center_y.rolling(window, min_periods=20).mean()\n",
    "            X[f'x_sl{window}'] = center_x.rolling(window, min_periods=20).std()\n",
    "            X[f'y_sl{window}'] = center_y.rolling(window, min_periods=20).std()\n",
    "\n",
    "    for span in [30, 60, 120]:\n",
    "        X[f'x_e{span}'] = center_x.ewm(span=span, min_periods=1).mean()\n",
    "        X[f'y_e{span}'] = center_y.ewm(span=span, min_periods=1).mean()\n",
    "\n",
    "    dist_from_center = np.sqrt((center_x - center_x.mean())**2 + (center_y - center_y.mean())**2)\n",
    "    for window in [30, 60, 120]:\n",
    "        X[f'cen_d{window}'] = dist_from_center.rolling(window, min_periods=5).mean()\n",
    "        X[f'cen_s{window}'] = dist_from_center.rolling(window, min_periods=5).std()\n",
    "\n",
    "    del dist_from_center\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_interaction_features(X, mouse_pair, avail_A, avail_B):\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "\n",
    "    rel_x = mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x']\n",
    "    rel_y = mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y']\n",
    "    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n",
    "\n",
    "    A_vx = mouse_pair['A']['body_center']['x'].diff()\n",
    "    A_vy = mouse_pair['A']['body_center']['y'].diff()\n",
    "    B_vx = mouse_pair['B']['body_center']['x'].diff()\n",
    "    B_vy = mouse_pair['B']['body_center']['y'].diff()\n",
    "\n",
    "    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n",
    "    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n",
    "\n",
    "    for window in [15, 30, 60, 120]:\n",
    "        X[f'A_ld{window}'] = A_lead.rolling(window, min_periods=5).mean()\n",
    "        X[f'B_ld{window}'] = B_lead.rolling(window, min_periods=5).mean()\n",
    "        X[f'A_ld_s{window}'] = A_lead.rolling(window, min_periods=5).std()\n",
    "        X[f'B_ld_s{window}'] = B_lead.rolling(window, min_periods=5).std()\n",
    "\n",
    "    approach = -rel_dist.diff()\n",
    "    chase = approach * B_lead\n",
    "    for window in [15, 30, 60, 120]:\n",
    "        X[f'chase_{window}'] = chase.rolling(window, min_periods=5).mean()\n",
    "        X[f'appr_{window}'] = approach.rolling(window, min_periods=5).mean()\n",
    "        X[f'chase_s{window}'] = chase.rolling(window, min_periods=5).std()\n",
    "\n",
    "    rel_angle = np.arctan2(rel_y, rel_x)\n",
    "    rel_angle_change = np.abs(rel_angle.diff())\n",
    "    for window in [30, 60, 120]:\n",
    "        X[f'rel_ang{window}'] = rel_angle_change.rolling(window, min_periods=5).sum()\n",
    "        X[f'rel_ang_m{window}'] = rel_angle_change.rolling(window, min_periods=5).mean()\n",
    "\n",
    "    del rel_x, rel_y, rel_dist, A_vx, A_vy, B_vx, B_vy, A_lead, B_lead, approach, chase, rel_angle, rel_angle_change\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_spatial_features(X, center_x, center_y):\n",
    "    grid_x = (center_x / 10).fillna(0).astype(int)\n",
    "    grid_y = (center_y / 10).fillna(0).astype(int)\n",
    "\n",
    "    for window in [60, 120, 240]:\n",
    "        if len(grid_x) >= window:\n",
    "            grid_changes = ((grid_x != grid_x.shift(1)) | (grid_y != grid_y.shift(1))).astype(float)\n",
    "            X[f'grid_ch{window}'] = grid_changes.rolling(window, min_periods=10).sum()\n",
    "\n",
    "    X['x_quad'] = (center_x > center_x.median()).astype(float)\n",
    "    X['y_quad'] = (center_y > center_y.median()).astype(float)\n",
    "\n",
    "    wall_dist = np.minimum(\n",
    "        np.minimum(center_x, 120 - center_x),\n",
    "        np.minimum(center_y, 120 - center_y)\n",
    "    )\n",
    "    X['wall_d'] = wall_dist\n",
    "    X['wall_d30'] = wall_dist.rolling(30, min_periods=5).mean()\n",
    "\n",
    "    del grid_x, grid_y, wall_dist\n",
    "    gc.collect()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_advanced_temporal_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "    \n",
    "    for window in [10, 20, 40]:\n",
    "        X[f'speed_accel_{window}'] = speed.diff().rolling(window, min_periods=5).mean()\n",
    "        X[f'speed_jerk_{window}'] = speed.diff().diff().rolling(window, min_periods=5).mean()\n",
    "    \n",
    "    for window in [30, 60]:\n",
    "        X[f'speed_skew_{window}'] = speed.rolling(window, min_periods=10).skew()\n",
    "        X[f'speed_kurt_{window}'] = speed.rolling(window, min_periods=10).kurt()\n",
    "    \n",
    "    del speed\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_posture_features(X, single_mouse):\n",
    "    if all(p in single_mouse.columns for p in ['nose', 'body_center', 'tail_base', 'ear_left', 'ear_right']):\n",
    "        head_width = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "                            (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
    "        body_length = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "                             (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
    "        \n",
    "        X['aspect_ratio'] = body_length / (head_width + 1e-6)\n",
    "        \n",
    "        for window in [15, 30, 60]:\n",
    "            X[f'aspect_m{window}'] = X['aspect_ratio'].rolling(window, min_periods=5).mean()\n",
    "            X[f'aspect_s{window}'] = X['aspect_ratio'].rolling(window, min_periods=5).std()\n",
    "        \n",
    "        del head_width, body_length\n",
    "        gc.collect()\n",
    "    \n",
    "    return X\n",
    "\n",
    "def add_behavioral_rhythm_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "    \n",
    "    for window in [90, 180]:\n",
    "        if len(speed) >= window:\n",
    "            fft_vals = speed.rolling(window, min_periods=window//2).apply(\n",
    "                lambda x: np.abs(np.fft.rfft(x - x.mean())[1:6]).max() if len(x) >= 10 else 0, raw=True\n",
    "            )\n",
    "            X[f'rhythm_peak_{window}'] = fft_vals\n",
    "    \n",
    "    for window in [60, 120]:\n",
    "        active = (speed > speed.quantile(0.6)).astype(float)\n",
    "        X[f'active_ratio_{window}'] = active.rolling(window, min_periods=10).mean()\n",
    "        del active\n",
    "        gc.collect()\n",
    "    \n",
    "    del speed\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_pair_synchrony_features(X, mouse_pair, avail_A, avail_B):\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "    \n",
    "    A_speed = np.sqrt(mouse_pair['A']['body_center']['x'].diff()**2 + \n",
    "                     mouse_pair['A']['body_center']['y'].diff()**2)\n",
    "    B_speed = np.sqrt(mouse_pair['B']['body_center']['x'].diff()**2 + \n",
    "                     mouse_pair['B']['body_center']['y'].diff()**2)\n",
    "    \n",
    "    for window in [30, 60, 120]:\n",
    "        A_norm = (A_speed - A_speed.rolling(window, min_periods=10).mean()) / (A_speed.rolling(window, min_periods=10).std() + 1e-6)\n",
    "        B_norm = (B_speed - B_speed.rolling(window, min_periods=10).mean()) / (B_speed.rolling(window, min_periods=10).std() + 1e-6)\n",
    "        X[f'sync_{window}'] = (A_norm * B_norm).rolling(window, min_periods=10).mean()\n",
    "        del A_norm, B_norm\n",
    "        gc.collect()\n",
    "    \n",
    "    for window in [30, 60]:\n",
    "        A_active = (A_speed > A_speed.quantile(0.6)).astype(float)\n",
    "        B_active = (B_speed > B_speed.quantile(0.6)).astype(float)\n",
    "        X[f'co_active_{window}'] = (A_active * B_active).rolling(window, min_periods=5).mean()\n",
    "        del A_active, B_active\n",
    "        gc.collect()\n",
    "    \n",
    "    speed_diff = np.abs(A_speed - B_speed)\n",
    "    for window in [30, 60]:\n",
    "        X[f'speed_diff_m{window}'] = speed_diff.rolling(window, min_periods=5).mean()\n",
    "        X[f'speed_diff_s{window}'] = speed_diff.rolling(window, min_periods=5).std()\n",
    "    \n",
    "    del A_speed, B_speed, speed_diff\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_spatial_context_features(X, center_x, center_y):\n",
    "    for window in [60, 120, 240]:\n",
    "        if len(center_x) >= window:\n",
    "            X[f'area_covered_{window}'] = (center_x.rolling(window, min_periods=10).max() - center_x.rolling(window, min_periods=10).min()) * \\\n",
    "                                          (center_y.rolling(window, min_periods=10).max() - center_y.rolling(window, min_periods=10).min())\n",
    "    \n",
    "    arena_center_x = 60.0\n",
    "    arena_center_y = 60.0\n",
    "    dist_to_arena_center = np.sqrt((center_x - arena_center_x)**2 + (center_y - arena_center_y)**2)\n",
    "    \n",
    "    for window in [30, 60, 120]:\n",
    "        X[f'center_pref_{window}'] = (dist_to_arena_center < 30).astype(float).rolling(window, min_periods=5).mean()\n",
    "    \n",
    "    del dist_to_arena_center\n",
    "    gc.collect()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b456f137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:19.368185Z",
     "iopub.status.busy": "2025-11-05T18:42:19.367880Z",
     "iopub.status.idle": "2025-11-05T18:42:19.380561Z",
     "shell.execute_reply": "2025-11-05T18:42:19.379960Z"
    },
    "papermill": {
     "duration": 0.018061,
     "end_time": "2025-11-05T18:42:19.381648",
     "exception": false,
     "start_time": "2025-11-05T18:42:19.363587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_momentum_features(X, center_x, center_y):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n",
    "    accel = speed.diff()\n",
    "    \n",
    "    for window in [10, 20, 40, 80]:\n",
    "        momentum = speed.rolling(window, min_periods=5).mean() * accel.rolling(window, min_periods=5).mean()\n",
    "        X[f'momentum_{window}'] = momentum\n",
    "        \n",
    "        speed_ewm = speed.ewm(span=window, min_periods=5).mean()\n",
    "        X[f'speed_momentum_{window}'] = speed_ewm * accel\n",
    "        \n",
    "        del momentum, speed_ewm\n",
    "        gc.collect()\n",
    "    \n",
    "    del speed, accel\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_directional_features(X, center_x, center_y):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    \n",
    "    direction = np.arctan2(vel_y, vel_x)\n",
    "    direction_change = direction.diff()\n",
    "    \n",
    "    for window in [15, 30, 60, 120]:\n",
    "        X[f'dir_std_{window}'] = direction.rolling(window, min_periods=5).std()\n",
    "        X[f'dir_range_{window}'] = direction.rolling(window, min_periods=5).max() - direction.rolling(window, min_periods=5).min()\n",
    "        X[f'dir_change_sum_{window}'] = np.abs(direction_change).rolling(window, min_periods=5).sum()\n",
    "        \n",
    "    persistence = (direction.diff().abs() < 0.1).astype(float)\n",
    "    for window in [30, 60]:\n",
    "        X[f'dir_persist_{window}'] = persistence.rolling(window, min_periods=5).mean()\n",
    "    \n",
    "    del vel_x, vel_y, direction, direction_change, persistence\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_acceleration_patterns(X, center_x, center_y):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    acc_x = vel_x.diff()\n",
    "    acc_y = vel_y.diff()\n",
    "    \n",
    "    acc_mag = np.sqrt(acc_x**2 + acc_y**2)\n",
    "    \n",
    "    for window in [10, 20, 40]:\n",
    "        X[f'acc_mean_{window}'] = acc_mag.rolling(window, min_periods=5).mean()\n",
    "        X[f'acc_std_{window}'] = acc_mag.rolling(window, min_periods=5).std()\n",
    "        X[f'acc_max_{window}'] = acc_mag.rolling(window, min_periods=5).max()\n",
    "        \n",
    "        burst = (acc_mag > acc_mag.quantile(0.75)).astype(float)\n",
    "        X[f'acc_burst_{window}'] = burst.rolling(window, min_periods=5).sum()\n",
    "        del burst\n",
    "        gc.collect()\n",
    "    \n",
    "    del vel_x, vel_y, acc_x, acc_y, acc_mag\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def add_relative_motion_features(X, mouse_pair, avail_A, avail_B):\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "    \n",
    "    A_vel_x = mouse_pair['A']['body_center']['x'].diff()\n",
    "    A_vel_y = mouse_pair['A']['body_center']['y'].diff()\n",
    "    B_vel_x = mouse_pair['B']['body_center']['x'].diff()\n",
    "    B_vel_y = mouse_pair['B']['body_center']['y'].diff()\n",
    "    \n",
    "    A_speed = np.sqrt(A_vel_x**2 + A_vel_y**2)\n",
    "    B_speed = np.sqrt(B_vel_x**2 + B_vel_y**2)\n",
    "    \n",
    "    rel_vel_x = A_vel_x - B_vel_x\n",
    "    rel_vel_y = A_vel_y - B_vel_y\n",
    "    rel_speed = np.sqrt(rel_vel_x**2 + rel_vel_y**2)\n",
    "    \n",
    "    for window in [15, 30, 60]:\n",
    "        X[f'rel_speed_m_{window}'] = rel_speed.rolling(window, min_periods=5).mean()\n",
    "        X[f'rel_speed_s_{window}'] = rel_speed.rolling(window, min_periods=5).std()\n",
    "        \n",
    "        speed_correlation = (A_speed * B_speed).rolling(window, min_periods=5).mean()\n",
    "        X[f'speed_corr_{window}'] = speed_correlation / (A_speed.rolling(window, min_periods=5).std() * B_speed.rolling(window, min_periods=5).std() + 1e-6)\n",
    "        \n",
    "        del speed_correlation\n",
    "        gc.collect()\n",
    "    \n",
    "    del A_vel_x, A_vel_y, B_vel_x, B_vel_y, A_speed, B_speed, rel_vel_x, rel_vel_y, rel_speed\n",
    "    gc.collect()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c3ca7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:19.389101Z",
     "iopub.status.busy": "2025-11-05T18:42:19.388895Z",
     "iopub.status.idle": "2025-11-05T18:42:19.431484Z",
     "shell.execute_reply": "2025-11-05T18:42:19.430754Z"
    },
    "papermill": {
     "duration": 0.047787,
     "end_time": "2025-11-05T18:42:19.432722",
     "exception": false,
     "start_time": "2025-11-05T18:42:19.384935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_single(single_mouse, body_parts_tracked):\n",
    "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"{p1}+{p2}\": np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n",
    "        if p1 in available_body_parts and p2 in available_body_parts\n",
    "    }, dtype=np.float32)\n",
    "    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n",
    "\n",
    "    if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n",
    "        for shift in [5, 10, 20]:\n",
    "            shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(shift)\n",
    "            speeds = pd.DataFrame({\n",
    "                f'sp_lf{shift}': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n",
    "                f'sp_rt{shift}': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
    "                f'sp_tb{shift}': np.square(single_mouse['tail_base'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "            }, dtype=np.float32)\n",
    "            X = pd.concat([X, speeds], axis=1)\n",
    "            del shifted, speeds\n",
    "            gc.collect()\n",
    "\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "        X['elong_inv'] = X['ear_left+ear_right'] / (X['nose+tail_base'] + 1e-6)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "        v1 = single_mouse['nose'] - single_mouse['body_center']\n",
    "        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
    "        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n",
    "            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n",
    "\n",
    "        for window in [15, 30, 60, 120]:\n",
    "            X[f'body_ang_m{window}'] = X['body_ang'].rolling(window, min_periods=5).mean()\n",
    "            X[f'body_ang_s{window}'] = X['body_ang'].rolling(window, min_periods=5).std()\n",
    "\n",
    "        del v1, v2\n",
    "        gc.collect()\n",
    "\n",
    "    if 'body_center' in available_body_parts:\n",
    "        cx = single_mouse['body_center']['x']\n",
    "        cy = single_mouse['body_center']['y']\n",
    "\n",
    "        for w in [5, 10, 15, 30, 60, 120]:\n",
    "            X[f'cx_m{w}'] = cx.rolling(w, min_periods=1, center=True).mean()\n",
    "            X[f'cy_m{w}'] = cy.rolling(w, min_periods=1, center=True).mean()\n",
    "            X[f'cx_s{w}'] = cx.rolling(w, min_periods=1, center=True).std()\n",
    "            X[f'cy_s{w}'] = cy.rolling(w, min_periods=1, center=True).std()\n",
    "            X[f'x_rng{w}'] = cx.rolling(w, min_periods=1, center=True).max() - cx.rolling(w, min_periods=1, center=True).min()\n",
    "            X[f'y_rng{w}'] = cy.rolling(w, min_periods=1, center=True).max() - cy.rolling(w, min_periods=1, center=True).min()\n",
    "            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(w, min_periods=1).sum()**2 + cy.diff().rolling(w, min_periods=1).sum()**2)\n",
    "            X[f'act{w}'] = np.sqrt(cx.diff().rolling(w, min_periods=1).var() + cy.diff().rolling(w, min_periods=1).var())\n",
    "\n",
    "        X = add_curvature_features(X, cx, cy)\n",
    "        X = add_multiscale_features(X, cx, cy)\n",
    "        X = add_state_features(X, cx, cy)\n",
    "        X = add_longrange_features(X, cx, cy)\n",
    "        X = add_spatial_features(X, cx, cy)\n",
    "        X = add_spectral_features(X, cx, cy)\n",
    "        X = add_advanced_temporal_features(X, cx, cy)\n",
    "        X = add_posture_features(X, single_mouse)\n",
    "        X = add_behavioral_rhythm_features(X, cx, cy)\n",
    "        X = add_spatial_context_features(X, cx, cy)\n",
    "        X = add_momentum_features(X, cx, cy)\n",
    "        X = add_directional_features(X, cx, cy)\n",
    "        X = add_acceleration_patterns(X, cx, cy)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n",
    "        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "                         (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
    "\n",
    "        for lag in [5, 10, 20, 40, 80]:\n",
    "            X[f'nt_lg{lag}'] = nt_dist.shift(lag)\n",
    "            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(lag)\n",
    "\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'nt_m{window}'] = nt_dist.rolling(window, min_periods=5).mean()\n",
    "            X[f'nt_s{window}'] = nt_dist.rolling(window, min_periods=5).std()\n",
    "            X[f'nt_mx{window}'] = nt_dist.rolling(window, min_periods=5).max()\n",
    "\n",
    "        del nt_dist\n",
    "        gc.collect()\n",
    "\n",
    "    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n",
    "        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "                       (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
    "\n",
    "        for off in [-40, -20, -10, 10, 20, 40]:\n",
    "            X[f'ear_o{off}'] = ear_d.shift(-off)\n",
    "\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'ear_m{window}'] = ear_d.rolling(window, min_periods=1, center=True).mean()\n",
    "            X[f'ear_s{window}'] = ear_d.rolling(window, min_periods=1, center=True).std()\n",
    "\n",
    "        X['ear_con'] = ear_d.rolling(30, min_periods=1, center=True).std() / (ear_d.rolling(30, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "        del ear_d\n",
    "        gc.collect()\n",
    "\n",
    "    if 'nose' in available_body_parts:\n",
    "        nose_speed = np.sqrt(single_mouse['nose']['x'].diff()**2 + single_mouse['nose']['y'].diff()**2)\n",
    "        for window in [15, 30, 60, 120]:\n",
    "            X[f'nose_sp{window}'] = nose_speed.rolling(window, min_periods=5).mean()\n",
    "            X[f'nose_sp_s{window}'] = nose_speed.rolling(window, min_periods=5).std()\n",
    "        del nose_speed\n",
    "        gc.collect()\n",
    "\n",
    "    if 'tail_base' in available_body_parts:\n",
    "        tail_speed = np.sqrt(single_mouse['tail_base']['x'].diff()**2 + single_mouse['tail_base']['y'].diff()**2)\n",
    "        for window in [15, 30, 60, 120]:\n",
    "            X[f'tail_sp{window}'] = tail_speed.rolling(window, min_periods=5).mean()\n",
    "            X[f'tail_sp_s{window}'] = tail_speed.rolling(window, min_periods=5).std()\n",
    "        del tail_speed\n",
    "        gc.collect()\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    gc.collect()\n",
    "    return X\n",
    "\n",
    "def transform_pair(mouse_pair, body_parts_tracked):\n",
    "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
    "        if p1 in avail_A and p2 in avail_B\n",
    "    }, dtype=np.float32)\n",
    "    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n",
    "\n",
    "    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "        for shift in [5, 10, 20]:\n",
    "            shA = mouse_pair['A']['ear_left'].shift(shift)\n",
    "            shB = mouse_pair['B']['ear_left'].shift(shift)\n",
    "            speeds = pd.DataFrame({\n",
    "                f'sp_A{shift}': np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n",
    "                f'sp_AB{shift}': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "                f'sp_B{shift}': np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "            }, dtype=np.float32)\n",
    "            X = pd.concat([X, speeds], axis=1)\n",
    "            del shA, shB, speeds\n",
    "            gc.collect()\n",
    "\n",
    "    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
    "        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
    "        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
    "        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n",
    "            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n",
    "\n",
    "        for window in [15, 30, 60, 120]:\n",
    "            X[f'rel_ori_m{window}'] = X['rel_ori'].rolling(window, min_periods=5).mean()\n",
    "            X[f'rel_ori_s{window}'] = X['rel_ori'].rolling(window, min_periods=5).std()\n",
    "\n",
    "        del dir_A, dir_B\n",
    "        gc.collect()\n",
    "\n",
    "    if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n",
    "        cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
    "\n",
    "        for lag in [5, 10, 20, 40, 80]:\n",
    "            shA_n = mouse_pair['A']['nose'].shift(lag)\n",
    "            shB_n = mouse_pair['B']['nose'].shift(lag)\n",
    "            past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
    "            X[f'appr{lag}'] = cur - past\n",
    "            del shA_n, shB_n, past\n",
    "            gc.collect()\n",
    "\n",
    "        del cur\n",
    "        gc.collect()\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                    (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "\n",
    "        X['v_cls'] = (cd < 5.0).astype(np.float32)\n",
    "        X['cls'] = ((cd >= 5.0) & (cd < 15.0)).astype(np.float32)\n",
    "        X['med'] = ((cd >= 15.0) & (cd < 30.0)).astype(np.float32)\n",
    "        X['far'] = (cd >= 30.0).astype(np.float32)\n",
    "\n",
    "        for window in [30, 60, 120, 240]:\n",
    "            X[f'v_cls_m{window}'] = X['v_cls'].rolling(window, min_periods=5).mean()\n",
    "            X[f'cls_m{window}'] = X['cls'].rolling(window, min_periods=5).mean()\n",
    "            X[f'med_m{window}'] = X['med'].rolling(window, min_periods=5).mean()\n",
    "\n",
    "        cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
    "\n",
    "        for w in [5, 10, 15, 30, 60, 120, 240]:\n",
    "            X[f'd_m{w}'] = cd_full.rolling(w, min_periods=1, center=True).mean()\n",
    "            X[f'd_s{w}'] = cd_full.rolling(w, min_periods=1, center=True).std()\n",
    "            X[f'd_mn{w}'] = cd_full.rolling(w, min_periods=1, center=True).min()\n",
    "            X[f'd_mx{w}'] = cd_full.rolling(w, min_periods=1, center=True).max()\n",
    "\n",
    "            d_var = cd_full.rolling(w, min_periods=1, center=True).var()\n",
    "            X[f'int{w}'] = 1 / (1 + d_var)\n",
    "            del d_var\n",
    "            gc.collect()\n",
    "\n",
    "        Axd = mouse_pair['A']['body_center']['x'].diff()\n",
    "        Ayd = mouse_pair['A']['body_center']['y'].diff()\n",
    "        Bxd = mouse_pair['B']['body_center']['x'].diff()\n",
    "        Byd = mouse_pair['B']['body_center']['y'].diff()\n",
    "\n",
    "        for w in [5, 10, 15, 30, 60, 120]:\n",
    "            coord = Axd * Bxd + Ayd * Byd\n",
    "            X[f'co_m{w}'] = coord.rolling(w, min_periods=1, center=True).mean()\n",
    "            X[f'co_s{w}'] = coord.rolling(w, min_periods=1, center=True).std()\n",
    "            del coord\n",
    "            gc.collect()\n",
    "\n",
    "        cd_change = cd.diff()\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'cd_ch{window}'] = cd_change.rolling(window, min_periods=5).sum()\n",
    "            X[f'cd_ch_s{window}'] = cd_change.rolling(window, min_periods=5).std()\n",
    "\n",
    "        val = (Axd * Bxd + Ayd * Byd) / (np.sqrt(Axd**2 + Ayd**2) * np.sqrt(Bxd**2 + Byd**2) + 1e-6)\n",
    "\n",
    "        for off in [-40, -20, -10, 0, 10, 20, 40]:\n",
    "            X[f'va_{off}'] = val.shift(-off)\n",
    "\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'va_m{window}'] = val.rolling(window, min_periods=5).mean()\n",
    "            X[f'va_s{window}'] = val.rolling(window, min_periods=5).std()\n",
    "\n",
    "        A_speed = np.sqrt(Axd**2 + Ayd**2)\n",
    "        B_speed = np.sqrt(Bxd**2 + Byd**2)\n",
    "        X['speed_ratio'] = A_speed / (B_speed + 1e-6)\n",
    "        X['speed_diff'] = A_speed - B_speed\n",
    "\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'A_sp{window}'] = A_speed.rolling(window, min_periods=5).mean()\n",
    "            X[f'B_sp{window}'] = B_speed.rolling(window, min_periods=5).mean()\n",
    "            X[f'sp_rat{window}'] = (A_speed / (B_speed + 1e-6)).rolling(window, min_periods=5).mean()\n",
    "\n",
    "        X = add_interaction_features(X, mouse_pair, avail_A, avail_B)\n",
    "        X = add_pair_synchrony_features(X, mouse_pair, avail_A, avail_B)\n",
    "        X = add_relative_motion_features(X, mouse_pair, avail_A, avail_B)\n",
    "\n",
    "        del cd, cd_full, cd_change, Axd, Ayd, Bxd, Byd, val, A_speed, B_speed\n",
    "        gc.collect()\n",
    "\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "                    (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
    "\n",
    "        for lag in [5, 10, 20, 40, 80]:\n",
    "            X[f'nn_lg{lag}'] = nn.shift(lag)\n",
    "            X[f'nn_ch{lag}'] = nn - nn.shift(lag)\n",
    "\n",
    "            is_cl = (nn < 10.0).astype(np.float32)\n",
    "            X[f'cl_ps{lag}'] = is_cl.rolling(lag, min_periods=1).mean()\n",
    "            del is_cl\n",
    "            gc.collect()\n",
    "\n",
    "        for window in [30, 60, 120, 240]:\n",
    "            X[f'nn_m{window}'] = nn.rolling(window, min_periods=5).mean()\n",
    "            X[f'nn_s{window}'] = nn.rolling(window, min_periods=5).std()\n",
    "            X[f'nn_mn{window}'] = nn.rolling(window, min_periods=5).min()\n",
    "\n",
    "        del nn\n",
    "        gc.collect()\n",
    "\n",
    "    if 'nose' in avail_A and 'body_center' in avail_B:\n",
    "        nose_to_body = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                               (mouse_pair['A']['nose']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'nb_m{window}'] = nose_to_body.rolling(window, min_periods=5).mean()\n",
    "            X[f'nb_s{window}'] = nose_to_body.rolling(window, min_periods=5).std()\n",
    "        del nose_to_body\n",
    "        gc.collect()\n",
    "\n",
    "    if 'body_center' in avail_A and 'nose' in avail_B:\n",
    "        body_to_nose = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "                               (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
    "        for window in [30, 60, 120]:\n",
    "            X[f'bn_m{window}'] = body_to_nose.rolling(window, min_periods=5).mean()\n",
    "            X[f'bn_s{window}'] = body_to_nose.rolling(window, min_periods=5).std()\n",
    "        del body_to_nose\n",
    "        gc.collect()\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    gc.collect()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c920379f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:19.440919Z",
     "iopub.status.busy": "2025-11-05T18:42:19.440286Z",
     "iopub.status.idle": "2025-11-05T18:42:19.444741Z",
     "shell.execute_reply": "2025-11-05T18:42:19.443927Z"
    },
    "papermill": {
     "duration": 0.009722,
     "end_time": "2025-11-05T18:42:19.445879",
     "exception": false,
     "start_time": "2025-11-05T18:42:19.436157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_action_thresholds = {\n",
    "    'attack': 0.11, 'sniff': 0.15, 'approach': 0.18, 'rear': 0.16,\n",
    "    'escape': 0.14, 'mount': 0.14, 'sniffbody': 0.17, 'selfgroom': 0.16,\n",
    "    'chase': 0.13, 'sniffface': 0.15, 'dig': 0.17, 'intromit': 0.15,\n",
    "    'defend': 0.16, 'reciprocalsniff': 0.15, 'climb': 0.16\n",
    "}\n",
    "\n",
    "action_thresholds = base_action_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a4877bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:19.453790Z",
     "iopub.status.busy": "2025-11-05T18:42:19.453287Z",
     "iopub.status.idle": "2025-11-05T18:42:19.464865Z",
     "shell.execute_reply": "2025-11-05T18:42:19.464301Z"
    },
    "papermill": {
     "duration": 0.016819,
     "end_time": "2025-11-05T18:42:19.466003",
     "exception": false,
     "start_time": "2025-11-05T18:42:19.449184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_multiclass_adaptive(pred, meta, action_thresholds):\n",
    "    pred = pred.astype(np.float32)\n",
    "\n",
    "    fps = meta['fps'].iloc[0] if 'fps' in meta.columns else 30\n",
    "    window_frames = int(11 * fps / 30)\n",
    "    window_frames = max(5, window_frames)\n",
    "\n",
    "    pred_smoothed = pred.rolling(window=window_frames, min_periods=1, center=True).mean()\n",
    "\n",
    "    for col in pred_smoothed.columns:\n",
    "        pred_smoothed[col] = gaussian_filter1d(pred_smoothed[col].fillna(0), sigma=2.5)\n",
    "\n",
    "    ama = np.argmax(pred_smoothed.values, axis=1)\n",
    "\n",
    "    max_probs = pred_smoothed.max(axis=1).values\n",
    "    threshold_mask = np.zeros(len(pred_smoothed), dtype=bool)\n",
    "    for i, action in enumerate(pred_smoothed.columns):\n",
    "        action_mask = (ama == i)\n",
    "        threshold = action_thresholds.get(action, 0.18)\n",
    "        threshold_mask |= (action_mask & (max_probs >= threshold))\n",
    "\n",
    "    ama = np.where(threshold_mask, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame.values)\n",
    "\n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "\n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes['video_id'].values[mask],\n",
    "        'agent_id': meta_changes['agent_id'].values[mask],\n",
    "        'target_id': meta_changes['target_id'].values[mask],\n",
    "        'action': pred.columns[ama_changes.values[mask]],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "\n",
    "    stop_video_id = meta_changes['video_id'].values[1:][mask[:-1]]\n",
    "    stop_agent_id = meta_changes['agent_id'].values[1:][mask[:-1]]\n",
    "    stop_target_id = meta_changes['target_id'].values[1:][mask[:-1]]\n",
    "\n",
    "    for i in range(len(submission_part)):\n",
    "        video_id = submission_part.video_id.iloc[i]\n",
    "        agent_id = submission_part.agent_id.iloc[i]\n",
    "        target_id = submission_part.target_id.iloc[i]\n",
    "        if i < len(stop_video_id):\n",
    "            if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n",
    "                new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "                submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "        else:\n",
    "            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "\n",
    "    min_duration = int(2 * fps / 30)\n",
    "    duration = submission_part.stop_frame - submission_part.start_frame\n",
    "    submission_part = submission_part[duration >= min_duration].reset_index(drop=True)\n",
    "\n",
    "    if len(submission_part) > 0:\n",
    "        assert (submission_part.stop_frame > submission_part.start_frame).all()\n",
    "\n",
    "    if verbose:\n",
    "        print(f'  actions found: {len(submission_part)}')\n",
    "\n",
    "    del pred_smoothed, ama, max_probs, threshold_mask\n",
    "    gc.collect()\n",
    "\n",
    "    return submission_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8783b6b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:19.473571Z",
     "iopub.status.busy": "2025-11-05T18:42:19.473325Z",
     "iopub.status.idle": "2025-11-05T18:42:19.482323Z",
     "shell.execute_reply": "2025-11-05T18:42:19.481707Z"
    },
    "papermill": {
     "duration": 0.014075,
     "end_time": "2025-11-05T18:42:19.483463",
     "exception": false,
     "start_time": "2025-11-05T18:42:19.469388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def robustify(submission, dataset, traintest, traintest_directory=None):\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "\n",
    "    submission = submission[submission.start_frame < submission.stop_frame]\n",
    "\n",
    "    group_list = []\n",
    "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
    "        group = group.sort_values('start_frame')\n",
    "        mask = np.ones(len(group), dtype=bool)\n",
    "        last_stop = 0\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            if row['start_frame'] < last_stop:\n",
    "                mask[i] = False\n",
    "            else:\n",
    "                last_stop = row['stop_frame']\n",
    "        group_list.append(group[mask])\n",
    "    submission = pd.concat(group_list) if group_list else submission\n",
    "\n",
    "    del group_list\n",
    "    gc.collect()\n",
    "\n",
    "    s_list = []\n",
    "    for idx, row in dataset.iterrows():\n",
    "        lab_id = row['lab_id']\n",
    "        if lab_id.startswith('MABe22'):\n",
    "            continue\n",
    "        video_id = row['video_id']\n",
    "        if (submission.video_id == video_id).any():\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Video {video_id} has no predictions\")\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path, columns=['video_frame'])\n",
    "\n",
    "        vid_behaviors = eval(row['behaviors_labeled'])\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "\n",
    "        start_frame = vid.video_frame.min()\n",
    "        stop_frame = vid.video_frame.max() + 1\n",
    "\n",
    "        for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n",
    "            batch_len = int(np.ceil((stop_frame - start_frame) / len(actions)))\n",
    "            for i, (_, action_row) in enumerate(actions.iterrows()):\n",
    "                batch_start = start_frame + i * batch_len\n",
    "                batch_stop = min(batch_start + batch_len, stop_frame)\n",
    "                s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n",
    "\n",
    "        del vid, vid_behaviors\n",
    "        gc.collect()\n",
    "\n",
    "    if len(s_list) > 0:\n",
    "        submission = pd.concat([\n",
    "            submission,\n",
    "            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n",
    "        ])\n",
    "\n",
    "    del s_list\n",
    "    gc.collect()\n",
    "\n",
    "    submission = submission.reset_index(drop=True)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b376dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:42:19.490916Z",
     "iopub.status.busy": "2025-11-05T18:42:19.490715Z",
     "iopub.status.idle": "2025-11-05T18:45:48.330462Z",
     "shell.execute_reply": "2025-11-05T18:45:48.329684Z"
    },
    "papermill": {
     "duration": 208.848867,
     "end_time": "2025-11-05T18:45:48.335619",
     "exception": false,
     "start_time": "2025-11-05T18:42:19.486752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Inference with Ensemble Models\n",
      "Starting Memory: 4.4%\n",
      "\n",
      "1. Processing: 18 body parts\n",
      "  n_videos: 1, n_models: 12\n",
      "video with missing values 438887472 test 529471 frames\n",
      "- test single 438887472 1\n",
      "  actions found: 9\n",
      "- test single 438887472 2\n",
      "  actions found: 44\n",
      "- test single 438887472 3\n",
      "  actions found: 37\n",
      "- test single 438887472 4\n",
      "  actions found: 82\n",
      "- test pair 438887472 1 2\n",
      "  actions found: 0\n",
      "- test pair 438887472 1 3\n",
      "  actions found: 0\n",
      "- test pair 438887472 1 4\n",
      "  actions found: 2\n",
      "- test pair 438887472 2 1\n",
      "  actions found: 5\n",
      "- test pair 438887472 2 3\n",
      "  actions found: 8\n",
      "- test pair 438887472 2 4\n",
      "  actions found: 15\n",
      "- test pair 438887472 3 1\n",
      "  actions found: 6\n",
      "- test pair 438887472 3 2\n",
      "  actions found: 9\n",
      "- test pair 438887472 3 4\n",
      "  actions found: 10\n",
      "- test pair 438887472 4 1\n",
      "  actions found: 19\n",
      "- test pair 438887472 4 2\n",
      "  actions found: 23\n",
      "- test pair 438887472 4 3\n",
      "  actions found: 24\n",
      "  Section 1 complete. Memory: 5.1%\n",
      "\n",
      "2. Processing: 14 body parts\n",
      "  n_videos: 0, n_models: 12\n",
      "  Section 2 complete. Memory: 5.1%\n",
      "\n",
      "3. Processing: 10 body parts\n",
      "  n_videos: 0, n_models: 12\n",
      "  Section 3 complete. Memory: 5.1%\n",
      "\n",
      "4. Processing: 8 body parts\n",
      "  n_videos: 0, n_models: 6\n",
      "  Section 4 complete. Memory: 5.1%\n",
      "\n",
      "5. Processing: 7 body parts\n",
      "  n_videos: 0, n_models: 6\n",
      "  Section 5 complete. Memory: 5.1%\n",
      "\n",
      "6. Processing: 5 body parts\n",
      "  n_videos: 0, n_models: 12\n",
      "  Section 6 complete. Memory: 5.1%\n",
      "\n",
      "7. Processing: 4 body parts\n",
      "  n_videos: 0, n_models: 12\n",
      "  Section 7 complete. Memory: 5.1%\n",
      "\n",
      "8. Processing: 7 body parts\n",
      "  n_videos: 0, n_models: 12\n",
      "  Section 8 complete. Memory: 5.1%\n",
      "\n",
      "9. Processing: 5 body parts\n",
      "  n_videos: 0, n_models: 12\n",
      "  Section 9 complete. Memory: 5.1%\n",
      "\n",
      "\n",
      "Final Memory before submission: 5.1%\n"
     ]
    }
   ],
   "source": [
    "submission_list = []\n",
    "\n",
    "print(f\"Starting Inference with Ensemble Models\")\n",
    "print(f\"Starting Memory: {psutil.virtual_memory().percent}%\\n\")\n",
    "\n",
    "for section in range(1, len(body_parts_tracked_list)):\n",
    "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "    try:\n",
    "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "        print(f\"{section}. Processing: {len(body_parts_tracked)} body parts\")\n",
    "        if len(body_parts_tracked) > 5:\n",
    "            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "        test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n",
    "        \n",
    "        model_files = {\n",
    "            'single': [],\n",
    "            'pair': []\n",
    "        }\n",
    "        \n",
    "        for model_type in ['xgb1', 'xgb2', 'xgb3', 'cat1', 'cat2', 'cat3']:\n",
    "            single_path = f'/kaggle/input/mabe-models/trained-models/{model_type}_single_{section}.pkl'\n",
    "            pair_path = f'/kaggle/input/mabe-models/trained-models/{model_type}_pair_{section}.pkl'\n",
    "            \n",
    "            if os.path.exists(single_path):\n",
    "                model_files['single'].append(single_path)\n",
    "            if os.path.exists(pair_path):\n",
    "                model_files['pair'].append(pair_path)\n",
    "        \n",
    "        if len(model_files['single']) == 0 and len(model_files['pair']) == 0:\n",
    "            print(f\"  No models found for section {section}\")\n",
    "            continue\n",
    "        \n",
    "        generator = generate_mouse_data(test_subset, 'test',\n",
    "                                        generate_single=(len(model_files['single']) > 0),\n",
    "                                        generate_pair=(len(model_files['pair']) > 0))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  n_videos: {len(test_subset)}, n_models: {len(model_files['single']) + len(model_files['pair'])}\")\n",
    "\n",
    "        video_counter = 0\n",
    "        for switch_te, data_te, meta_te, actions_te in generator:\n",
    "            try:\n",
    "                if switch_te == 'single':\n",
    "                    X_te = transform_single(data_te, body_parts_tracked)\n",
    "                    model_paths = model_files['single']\n",
    "                else:\n",
    "                    X_te = transform_pair(data_te, body_parts_tracked)\n",
    "                    model_paths = model_files['pair']\n",
    "\n",
    "                if verbose and len(X_te) == 0:\n",
    "                    print(\"ERROR: X_te empty\")\n",
    "                del data_te\n",
    "                gc.collect()\n",
    "\n",
    "                pred = pd.DataFrame(index=meta_te.video_frame, dtype=np.float32)\n",
    "                \n",
    "                all_actions = set()\n",
    "                all_models = []\n",
    "                \n",
    "                for model_path in model_paths:\n",
    "                    with open(model_path, 'rb') as f:\n",
    "                        model_list = pickle.load(f)\n",
    "                        all_models.append(model_list)\n",
    "                        for action, _ in model_list:\n",
    "                            all_actions.add(action)\n",
    "                \n",
    "                for action in all_actions:\n",
    "                    if action in actions_te:\n",
    "                        probs = []\n",
    "                        \n",
    "                        for model_list in all_models:\n",
    "                            for act, trained_model in model_list:\n",
    "                                if act == action:\n",
    "                                    prob = trained_model.predict_proba(X_te)[:, 1]\n",
    "                                    probs.append(prob)\n",
    "                                    del prob\n",
    "                                    gc.collect()\n",
    "                        \n",
    "                        if len(probs) > 0:\n",
    "                            pred[action] = np.mean(probs, axis=0)\n",
    "                            del probs\n",
    "                            gc.collect()\n",
    "\n",
    "                del X_te, all_models\n",
    "                gc.collect()\n",
    "\n",
    "                if pred.shape[1] != 0:\n",
    "                    sub_part = predict_multiclass_adaptive(pred, meta_te, action_thresholds)\n",
    "                    submission_list.append(sub_part)\n",
    "                    del sub_part\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(f\"  ERROR: no training data\")\n",
    "\n",
    "                del pred, meta_te\n",
    "\n",
    "                video_counter += 1\n",
    "                if video_counter % 2 == 0:\n",
    "                    gc.collect()\n",
    "                    if CUPY_AVAILABLE:\n",
    "                        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f'  ERROR: {str(e)[:50]}')\n",
    "                try:\n",
    "                    del data_te\n",
    "                except:\n",
    "                    pass\n",
    "                gc.collect()\n",
    "\n",
    "        mem_current = psutil.virtual_memory().percent\n",
    "        print(f\"  Section {section} complete. Memory: {mem_current}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'***Exception*** {str(e)[:100]}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "    gc.collect()\n",
    "    if CUPY_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print()\n",
    "\n",
    "print(f\"\\nFinal Memory before submission: {psutil.virtual_memory().percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e25595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T18:45:48.344839Z",
     "iopub.status.busy": "2025-11-05T18:45:48.344052Z",
     "iopub.status.idle": "2025-11-05T18:45:48.676436Z",
     "shell.execute_reply": "2025-11-05T18:45:48.675515Z"
    },
    "papermill": {
     "duration": 0.338104,
     "end_time": "2025-11-05T18:45:48.677623",
     "exception": false,
     "start_time": "2025-11-05T18:45:48.339519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission created: 293 predictions\n",
      "Final Memory: 5.1%\n"
     ]
    }
   ],
   "source": [
    "if len(submission_list) > 0:\n",
    "    submission = pd.concat(submission_list)\n",
    "    del submission_list\n",
    "    gc.collect()\n",
    "else:\n",
    "    submission = pd.DataFrame({\n",
    "        'video_id': [438887472],\n",
    "        'agent_id': ['mouse1'],\n",
    "        'target_id': ['self'],\n",
    "        'action': ['rear'],\n",
    "        'start_frame': [278],\n",
    "        'stop_frame': [500]\n",
    "    })\n",
    "\n",
    "submission_robust = robustify(submission, test, 'test')\n",
    "del submission\n",
    "gc.collect()\n",
    "\n",
    "submission_robust.index.name = 'row_id'\n",
    "submission_robust.to_csv('submission.csv')\n",
    "print(f\"\\nSubmission created: {len(submission_robust)} predictions\")\n",
    "print(f\"Final Memory: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "del submission_robust\n",
    "gc.collect()\n",
    "if CUPY_AVAILABLE:\n",
    "    cp.get_default_memory_pool().free_all_blocks()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    },
    {
     "datasetId": 8657309,
     "sourceId": 13626931,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 225.401117,
   "end_time": "2025-11-05T18:45:49.299017",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-05T18:42:03.897900",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
